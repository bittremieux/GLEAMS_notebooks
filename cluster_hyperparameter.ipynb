{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['GLEAMS_HOME'] = os.path.join(os.environ['HOME'],\n",
    "                                         'Projects/gleams')\n",
    "# Make sure all code is in the PATH.\n",
    "sys.path.append(\n",
    "    os.path.normpath(os.path.join(os.environ['GLEAMS_HOME'], 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import EfficiencyWarning\n",
    "warnings.simplefilter(action='ignore', category=EfficiencyWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import skopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('gleams')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gleams.dag import dag\n",
    "\n",
    "from gleams import config\n",
    "from gleams.cluster import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styling.\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='serif')\n",
    "sns.set_palette('Set1')\n",
    "sns.set_context('paper', font_scale=1.3)    # Single-column figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_filename = os.path.join(\n",
    "    os.environ['GLEAMS_HOME'], 'data', 'ann',\n",
    "    f'clusters_{config.massivekb_task_id}_{split}.npy')\n",
    "metadata_ident_filename = os.path.join(\n",
    "    os.environ['GLEAMS_HOME'], 'data', 'metadata',\n",
    "    f'metadata_{config.massivekb_task_id}_{split}.parquet')\n",
    "metadata_all_filename = os.path.join(\n",
    "    os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "    f'embed_{config.massivekb_task_id}_{split}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.build_ann_index(\n",
    "    os.path.join(os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "                 f'embed_{config.massivekb_task_id}_{split}.npy'))\n",
    "cluster.compute_pairwise_distances(\n",
    "    os.path.join(os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "                 f'embed_{config.massivekb_task_id}_{split}.npy'),\n",
    "    os.path.join(os.environ['GLEAMS_HOME'], 'data', 'ann',\n",
    "                 f'ann_{config.massivekb_task_id}_{split}.faiss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.merge(pd.read_parquet(metadata_all_filename),\n",
    "                    pd.read_parquet(metadata_ident_filename),\n",
    "                    'left', ['dataset', 'filename', 'scan'])\n",
    "# Don't disambiguate between I/L.\n",
    "metadata['sequence'] = metadata['sequence'].str.replace('I', 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clusters(clusters_filename, min_peptide_size=None):\n",
    "    # Only consider identified spectra as clustering ground truth.\n",
    "    clusters = (pd.DataFrame({'sequence': metadata['sequence'],\n",
    "                              'cluster': np.load(clusters_filename)})\n",
    "                .dropna())\n",
    "    # Possibly only consider clusters of a minimal size.\n",
    "    # (Is the clustering better for small/large clusters?)\n",
    "    if min_peptide_size is not None:\n",
    "        peptide_counts = clusters['sequence'].value_counts()\n",
    "        clusters = clusters[clusters['sequence'].isin(\n",
    "            peptide_counts[peptide_counts >= min_peptide_size].index)]\n",
    "    clusters_non_noise = clusters[clusters['cluster'] != -1]\n",
    "    prop_clustered = len(clusters_non_noise) / len(clusters)\n",
    "    prop_clustered_incorrect = (\n",
    "            clusters_non_noise.groupby('cluster')['sequence']\n",
    "            .apply(lambda labels: len(labels) - labels.value_counts().iat[0])\n",
    "            .sum()\n",
    "            / len(clusters))\n",
    "\n",
    "    return prop_clustered, prop_clustered_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_peptide_size = 5\n",
    "max_prop_clustered_incorrect = 0.01\n",
    "\n",
    "\n",
    "def optimize_cluster_hyperparameters(args):\n",
    "    config.eps, config.min_samples = args\n",
    "    if os.path.isfile(cluster_filename):\n",
    "        os.remove(cluster_filename)\n",
    "    cluster.cluster(os.path.join(\n",
    "        os.environ['GLEAMS_HOME'], 'data', 'ann',\n",
    "        f'dist_{config.massivekb_task_id}_{split}.npz'))\n",
    "    prop_clustered, prop_clustered_incorrect = evaluate_clusters(\n",
    "        cluster_filename, min_peptide_size)\n",
    "    props_clustered.append(prop_clustered)\n",
    "    props_clustered_incorrect.append(prop_clustered_incorrect)\n",
    "    if prop_clustered_incorrect > max_prop_clustered_incorrect:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 - prop_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props_clustered, props_clustered_incorrect = [], []\n",
    "optim = skopt.gp_minimize(optimize_cluster_hyperparameters,\n",
    "                          [skopt.space.Real(0.0001, 0.1, name='eps'),\n",
    "                           skopt.space.Integer(2, 10, name='min_samples')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_hyperparameter = pd.DataFrame(\n",
    "    {'eps': np.asarray(optim.x_iters)[:, 0],\n",
    "     'min_samples': np.asarray(optim.x_iters)[:, 1],\n",
    "     'prop_clustered': props_clustered,\n",
    "     'prop_clustered_incorrect': props_clustered_incorrect})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove final (suboptimal) clustering.\n",
    "os.remove(cluster_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(cluster_hyperparameter, 'cluster_hyperparameter.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_hyperparameter = joblib.load('cluster_hyperparameter.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pareto_frontier(arr):\n",
    "    # Sort by the first column.\n",
    "    arr_sorted = arr[arr[:, 0].argsort()]\n",
    "    # Iteratively add points to the Pareto frontier.\n",
    "    pareto_idx = [0]\n",
    "    for i in range(1, arr_sorted.shape[0]):\n",
    "        if (arr_sorted[i, 0] > arr_sorted[pareto_idx[-1], 0] and\n",
    "                arr_sorted[i, 1] > arr_sorted[pareto_idx[-1], 1]):\n",
    "            pareto_idx.append(i)\n",
    "    return arr_sorted[pareto_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_hyperparam = cluster_hyperparameter[\n",
    "    cluster_hyperparameter['prop_clustered_incorrect'] < 0.01]\n",
    "best_hyperparam = acceptable_hyperparam.loc[\n",
    "    acceptable_hyperparam['prop_clustered'].idxmax()]\n",
    "print(f'Optimal clustering hyperparameters:\\n'\n",
    "      f'  - eps = {best_hyperparam[\"eps\"]:.4f}\\n'\n",
    "      f'  - min_samples = {best_hyperparam[\"min_samples\"]:.0f}\\n'\n",
    "      f'-> {best_hyperparam[\"prop_clustered\"]:.2%} clustered, '\n",
    "      f'{best_hyperparam[\"prop_clustered_incorrect\"]:.2%} clustered incorrectly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618    # golden ratio\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "clustering_pareto = get_pareto_frontier(np.column_stack(\n",
    "    [cluster_hyperparameter['prop_clustered_incorrect'],\n",
    "     cluster_hyperparameter['prop_clustered']]))\n",
    "ax.plot(clustering_pareto[:, 0], clustering_pareto[:, 1], marker='o')\n",
    "scatter = ax.scatter(cluster_hyperparameter['prop_clustered_incorrect'],\n",
    "                     cluster_hyperparameter['prop_clustered'], marker='.')\n",
    "ax.axvline(max_prop_clustered_incorrect, c='darkgray', ls='--')\n",
    "\n",
    "ax.set_xlim(-0.005, 0.1)\n",
    "ax.set_ylim(-0.05, 1)\n",
    "\n",
    "ax.set_xlabel('Incorrectly clustered spectra')\n",
    "ax.set_ylabel('Clustered spectra')\n",
    "\n",
    "ax.xaxis.set_major_formatter(mticker.PercentFormatter(1))\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(1))\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('cluster_hyperparameter.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
