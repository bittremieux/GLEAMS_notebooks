{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['GLEAMS_HOME'] = os.path.join(os.environ['HOME'],\n",
    "                                         'Projects/gleams')\n",
    "# Make sure all code is in the PATH.\n",
    "sys.path.append(\n",
    "    os.path.normpath(os.path.join(os.environ['GLEAMS_HOME'], 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.exceptions import EfficiencyWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('gleams')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=EfficiencyWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gleams.dag import dag\n",
    "\n",
    "from gleams import config\n",
    "from gleams.cluster import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styling.\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='serif')\n",
    "sns.set_palette('Set1')\n",
    "sns.set_context('paper', font_scale=1.3)    # Single-column figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.build_ann_index(\n",
    "    os.path.join(os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "                 f'embed_{config.massivekb_task_id}_{split}.npy'))\n",
    "cluster.compute_pairwise_distances(\n",
    "    os.path.join(os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "                 f'embed_{config.massivekb_task_id}_{split}.npy'),\n",
    "    os.path.join(os.environ['GLEAMS_HOME'], 'data', 'ann',\n",
    "                 f'ann_{config.massivekb_task_id}_{split}.faiss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clusters(clusters_filename: str, metadata_ident_filename: str,\n",
    "                      metadata_all_filename: str,\n",
    "                      min_peptide_size: int = None):\n",
    "    clusters = pd.merge(pd.read_parquet(metadata_all_filename),\n",
    "                        pd.read_parquet(metadata_ident_filename),\n",
    "                        'left', ['dataset', 'filename', 'scan'])\n",
    "    # Don't disambiguate between I/L.\n",
    "    clusters['sequence'] = clusters['sequence'].str.replace('I', 'L')\n",
    "    clusters['cluster'] = np.load(clusters_filename)\n",
    "    # Only consider identified spectra as clustering ground truth.\n",
    "    clusters_ident = clusters.dropna(subset=['sequence'])\n",
    "    # Possibly only consider clusters of a minimal size.\n",
    "    # (Is the clustering better for small/large clusters?)\n",
    "    if min_peptide_size is not None:\n",
    "        peptide_counts = clusters_ident['sequence'].value_counts()\n",
    "        clusters_ident = clusters_ident[clusters_ident['sequence'].isin(\n",
    "            peptide_counts[peptide_counts >= min_peptide_size].index)]\n",
    "    clusters_ident_non_noise = clusters_ident[clusters_ident['cluster'] != -1]\n",
    "    prop_clustered = len(clusters_ident_non_noise) / len(clusters_ident)\n",
    "    prop_clustered_incorrect = (\n",
    "            clusters_ident_non_noise.groupby('cluster')['sequence']\n",
    "            .apply(lambda labels: len(labels) - labels.value_counts().iat[0])\n",
    "            .sum()\n",
    "            / len(clusters_ident))\n",
    "\n",
    "    return prop_clustered, prop_clustered_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_filename = os.path.join(\n",
    "    os.environ['GLEAMS_HOME'], 'data', 'ann',\n",
    "    f'clusters_{config.massivekb_task_id}_{split}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Cluster hyperparameter search')\n",
    "cluster_hyperparameter = [], [], [], []\n",
    "min_peptide_size = 5\n",
    "for eps in np.arange(0.01, 0.051, 0.005):\n",
    "    for min_samples in [2, 3, 5, 10]:\n",
    "        config.eps = eps\n",
    "        config.min_samples = min_samples\n",
    "        if os.path.isfile(cluster_filename):\n",
    "            os.remove(cluster_filename)\n",
    "        cluster.cluster(os.path.join(\n",
    "            os.environ['GLEAMS_HOME'], 'data', 'ann',\n",
    "            f'dist_{config.massivekb_task_id}_{split}.npz'))\n",
    "        prop_clustered, prop_clustered_incorrect = evaluate_clusters(\n",
    "            cluster_filename,\n",
    "            os.path.join(os.environ['GLEAMS_HOME'], 'data', 'metadata',\n",
    "                         f'metadata_{config.massivekb_task_id}_{split}.parquet'),\n",
    "            os.path.join(os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "                         f'embed_{config.massivekb_task_id}_{split}.parquet'),\n",
    "            min_peptide_size)\n",
    "        logger.debug(f'Clustered = {prop_clustered:.2%}, '\n",
    "                     f'incorrectly clustered = '\n",
    "                     f'{prop_clustered_incorrect:.2%}')\n",
    "        cluster_hyperparameter[0].append(config.eps)\n",
    "        cluster_hyperparameter[1].append(config.min_samples)\n",
    "        cluster_hyperparameter[2].append(prop_clustered)\n",
    "        cluster_hyperparameter[3].append(prop_clustered_incorrect)\n",
    "cluster_hyperparameter = pd.DataFrame(\n",
    "    {'eps': cluster_hyperparameter[0],\n",
    "     'min_samples': cluster_hyperparameter[1],\n",
    "     'prop_clustered': cluster_hyperparameter[2],\n",
    "     'prop_clustered_incorrect': cluster_hyperparameter[3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove final (suboptimal) clustering.\n",
    "os.remove(cluster_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(cluster_hyperparameter, 'cluster_hyperparameter.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_hyperparameter = joblib.load('cluster_hyperparameter.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pareto_frontier(arr):\n",
    "    # Sort by the first column.\n",
    "    arr_sorted = arr[arr[:, 0].argsort()]\n",
    "    # Iteratively add points to the Pareto frontier.\n",
    "    pareto_idx = [0]\n",
    "    for i in range(1, arr_sorted.shape[0]):\n",
    "        if (arr_sorted[i, 0] > arr_sorted[pareto_idx[-1], 0] and\n",
    "                arr_sorted[i, 1] > arr_sorted[pareto_idx[-1], 1]):\n",
    "            pareto_idx.append(i)\n",
    "    return arr_sorted[pareto_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_hyperparam = cluster_hyperparameter[\n",
    "    cluster_hyperparameter['prop_clustered_incorrect'] < 0.01]\n",
    "best_hyperparam = acceptable_hyperparam.iloc[\n",
    "    acceptable_hyperparam['prop_clustered'].idxmax()]\n",
    "print(f'Optimal clustering hyperparameters:\\n'\n",
    "      f'  - eps = {best_hyperparam[\"eps\"]:.4f}\\n'\n",
    "      f'  - min_samples = {best_hyperparam[\"min_samples\"]:.0f}\\n'\n",
    "      f'-> {best_hyperparam[\"prop_clustered\"]:.2%} clustered, '\n",
    "      f'{best_hyperparam[\"prop_clustered_incorrect\"]:.2%} clustered incorrectly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618    # golden ratio\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "clustering_pareto = get_pareto_frontier(np.column_stack(\n",
    "    [cluster_hyperparameter['prop_clustered_incorrect'],\n",
    "     cluster_hyperparameter['prop_clustered']]))\n",
    "ax.plot(clustering_pareto[:, 0], clustering_pareto[:, 1], marker='o')\n",
    "scatter = ax.scatter(cluster_hyperparameter['prop_clustered_incorrect'],\n",
    "                     cluster_hyperparameter['prop_clustered'], marker='.')\n",
    "ax.scatter(best_hyperparam['prop_clustered_incorrect'],\n",
    "           best_hyperparam['prop_clustered'],\n",
    "           s=200, c=scatter.get_facecolors(), marker='D')\n",
    "\n",
    "# ax.set_xlim(-0.001, 0.015)\n",
    "ax.set_ylim(-0.05, 1)\n",
    "\n",
    "ax.set_xlabel('Incorrectly clustered spectra')\n",
    "ax.set_ylabel('Clustered spectra')\n",
    "\n",
    "ax.xaxis.set_major_formatter(mticker.PercentFormatter(1))\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(1))\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('cluster_hyperparameter.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
