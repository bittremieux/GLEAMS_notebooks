{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['GLEAMS_HOME'] = os.path.join(os.environ['HOME'],\n",
    "                                         'Projects/gleams')\n",
    "# Make sure all code is in the PATH.\n",
    "sys.path.append(\n",
    "    os.path.normpath(os.path.join(os.environ['GLEAMS_HOME'], 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import EfficiencyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=EfficiencyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import itertools\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyteomics\n",
    "import seaborn as sns\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging.\n",
    "from gleams import logger as glogger\n",
    "glogger.init()\n",
    "# Initialize all random seeds before importing any packages.\n",
    "from gleams import rndm\n",
    "rndm.set_seeds()\n",
    "\n",
    "from gleams import config\n",
    "from gleams.cluster import cluster\n",
    "from gleams.feature import feature, spectrum\n",
    "from gleams.ms_io import ms_io\n",
    "from gleams.nn import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('gleams')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styling.\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='serif')\n",
    "sns.set_palette('Set1')\n",
    "sns.set_context('paper', font_scale=1.3)    # Single-column figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p $GLEAMS_HOME/notebooks/cluster_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dir = os.path.join(\n",
    "    os.environ['GLEAMS_HOME'], 'notebooks', 'cluster_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectra_from_file(dataset, filename, scans):\n",
    "    logger.debug('Process file %s/%s', dataset, filename)\n",
    "    peak_filename = os.path.join(os.environ['GLEAMS_HOME'], 'data', 'peak',\n",
    "                                 dataset, filename)\n",
    "    if os.path.isfile(peak_filename):\n",
    "        return [spec for spec in ms_io.get_spectra(peak_filename, scans)\n",
    "                if spectrum.preprocess(copy.deepcopy(spec),\n",
    "                                       config.fragment_mz_min,\n",
    "                                       config.fragment_mz_max).is_valid]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_mgf = os.path.join(cluster_dir, 'cluster_comparison.mgf')\n",
    "filename_metadata = os.path.join(cluster_dir, 'cluster_comparison.parquet')\n",
    "split = 'test'\n",
    "if not os.path.isfile(filename_metadata):\n",
    "    logger.info('Export spectra to be clustered to MGF file(s)')\n",
    "    datasets = pd.read_parquet(\n",
    "        os.path.join(os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "                     f'embed_{config.massivekb_task_id}_{split}.parquet'))\n",
    "    dataset_filename_scans = (datasets.groupby(['dataset', 'filename'])\n",
    "                              ['scan'].apply(list).reset_index())\n",
    "    spectrum_idx = []\n",
    "    for i, (dataset, filename_scans) in tqdm.tqdm(\n",
    "            enumerate(dataset_filename_scans.groupby('dataset'), 1),\n",
    "            desc='Datasets processed',\n",
    "            total=dataset_filename_scans['dataset'].nunique()):\n",
    "        for filename, spectra in zip(\n",
    "                filename_scans['filename'],\n",
    "                joblib.Parallel(n_jobs=-1, backend='multiprocessing')(\n",
    "                    joblib.delayed(get_spectra_from_file)\n",
    "                    (dataset, filename, scans)\n",
    "                    for filename, scans in zip(filename_scans['filename'],\n",
    "                                               filename_scans['scan']))):\n",
    "            if spectra is not None:\n",
    "                spectra_dicts = []\n",
    "                for spec in spectra:\n",
    "                    spectra_dicts.append(\n",
    "                        {'m/z array': spec.mz,\n",
    "                        'intensity array': spec.intensity,\n",
    "                        'params': {\n",
    "                            'TITLE': len(spectrum_idx),\n",
    "                            'RTINSECONDS': spec.retention_time,\n",
    "                            'PEPMASS': spec.precursor_mz,\n",
    "                            'CHARGE': f'{spec.precursor_charge}+'}})\n",
    "                    spectrum_idx.append((dataset, filename,\n",
    "                                         int(spec.identifier)))\n",
    "                with open(filename_mgf, 'a') as f:\n",
    "                    pyteomics.mgf.write(spectra_dicts, f)\n",
    "    psms = pd.read_parquet(\n",
    "        os.path.join(os.environ['GLEAMS_HOME'], 'data', 'metadata',\n",
    "                     f'massivekb_ids_{config.massivekb_task_id}.parquet'))\n",
    "    metadata = pd.merge(\n",
    "        pd.DataFrame(spectrum_idx, columns=['dataset', 'filename', 'scan']),\n",
    "        psms, 'left', ['dataset', 'filename', 'scan'])\n",
    "    metadata['sequence'] = metadata['sequence'].str.replace('I', 'L')\n",
    "    metadata.to_parquet(filename_metadata)\n",
    "else:\n",
    "    metadata = pd.read_parquet(filename_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size = 2\n",
    "min_peptide_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clusters(clusters, min_cluster_size=None,\n",
    "                      min_peptide_size=None):\n",
    "    # Ignore small clusters.\n",
    "    if min_cluster_size is not None:\n",
    "        cluster_counts = clusters['cluster'].value_counts()\n",
    "        clusters.loc[clusters['cluster'].isin(cluster_counts[\n",
    "            cluster_counts < min_cluster_size].index), 'cluster'] = -1\n",
    "    # Only expect frequently occuring peptides to be clustered.\n",
    "    if min_peptide_size is not None:\n",
    "        peptide_counts = clusters['sequence'].value_counts()\n",
    "        clusters = clusters[clusters['sequence'].isin(\n",
    "            peptide_counts[peptide_counts >= min_peptide_size].index)]\n",
    "    clusters_non_noise = clusters[clusters['cluster'] != -1]\n",
    "    prop_clustered = len(clusters_non_noise) / len(clusters)\n",
    "    prop_clustered_incorrect = (\n",
    "            clusters_non_noise.groupby('cluster')['sequence']\n",
    "            .apply(lambda labels: len(labels) - labels.value_counts().iat[0])\n",
    "            .sum()\n",
    "            / len(clusters))\n",
    "\n",
    "    return prop_clustered, prop_clustered_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = collections.defaultdict(list)\n",
    "timing = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MS-Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_mscluster = os.path.join(cluster_dir, 'mscluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p $GLEAMS_HOME/notebooks/cluster_comparison/mscluster\n",
    "ls $GLEAMS_HOME/notebooks/cluster_comparison/cluster_comparison.mgf \\\n",
    "    > $GLEAMS_HOME/notebooks/cluster_comparison/mscluster/mscluster_spec_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "time $GLEAMS_HOME/bin/MsCluster/MsCluster \\\n",
    "    --model LTQ_TRYP \\\n",
    "    --list $GLEAMS_HOME/notebooks/cluster_comparison/mscluster/mscluster_spec_list.txt \\\n",
    "    --output-name mscluster \\\n",
    "    --tmp-dir $GLEAMS_HOME/notebooks/cluster_comparison/mscluster/dat \\\n",
    "    --out-dir $GLEAMS_HOME/notebooks/cluster_comparison/mscluster \\\n",
    "    --dat-only \\\n",
    "    --model-dir $GLEAMS_HOME/bin/MsCluster/Models \\\n",
    "    --keep-dat \\\n",
    "    --assign-charges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MS-Cluster hyperparameters that influence the clustering quality are:\n",
    "\n",
    "- `--mixture-prob <X>`: the probability wrongfully adding a spectrum to a cluster (default X=0.05)\n",
    "- `--num-rounds <X>`: determines how many rounds are used for the hierarchical clustering (default X=3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mscluster = list(itertools.product(\n",
    "    [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1], [3, 5, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (mixture_prob, num_rounds) in enumerate(hp_mscluster):\n",
    "    logger.info('MS-Cluster run %d (mixture-prob=%.3f ; num-rounds=%d)',\n",
    "                i + 1, mixture_prob, num_rounds)\n",
    "    # Execute clustering.\n",
    "    cmd = f\"\"\"$GLEAMS_HOME/bin/MsCluster/MsCluster \\\n",
    "        --model LTQ_TRYP \\\n",
    "        --dat-list {dir_mscluster}/dat/mscluster_dat_list.txt \\\n",
    "        --output-name mscluster \\\n",
    "        --output-file-size 100000000 \\\n",
    "        --out-dir {dir_mscluster}/cluster_{i} \\\n",
    "        --model-dir $GLEAMS_HOME/bin/MsCluster/Models \\\n",
    "        --memory-gb 20 \\\n",
    "        --fragment-tolerance 0.05 \\\n",
    "        --precursor-ppm 10 \\\n",
    "        --assign-charges \\\n",
    "        --mixture-prob {mixture_prob} \\\n",
    "        --num-rounds {num_rounds} \\\n",
    "        --keep-dataset-idx\"\"\"\n",
    "    start_time = time.time()\n",
    "    if not os.path.isfile(os.path.join(dir_mscluster, f'cluster_{i}',\n",
    "                                       'mscluster_0_0_mgf_list.txt')):\n",
    "        ! eval {cmd}\n",
    "        # Account for failed MS-Cluster runs.\n",
    "        if not os.path.isfile(os.path.join(dir_mscluster, f'cluster_{i}',\n",
    "                                           'mscluster_0_0_mgf_list.txt')):\n",
    "            continue\n",
    "        timing['MS-Cluster'].append(time.time() - start_time)\n",
    "    else:\n",
    "        timing['MS-Cluster'].append(np.nan)\n",
    "    # Evaluate clustering performance.\n",
    "    cluster_labels, cluster_i = np.full(len(metadata), -1), -1\n",
    "    for filename in os.listdir(os.path.join(dir_mscluster, f'cluster_{i}',\n",
    "                                            'clust')):\n",
    "        if filename.endswith('.clust'):\n",
    "            with open(os.path.join(dir_mscluster, f'cluster_{i}', 'clust',\n",
    "                                   filename)) as f_in:\n",
    "                for line in f_in:\n",
    "                    if line.startswith('mscluster'):\n",
    "                        cluster_i += 1\n",
    "                    elif not line.isspace():\n",
    "                        cluster_labels[int(line.split('\\t')[2])] = cluster_i\n",
    "    performance['MS-Cluster'].append(\n",
    "        evaluate_clusters(pd.DataFrame({'sequence': metadata['sequence'],\n",
    "                                        'cluster': cluster_labels}).dropna(),\n",
    "                          min_cluster_size, min_peptide_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spectra-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_spectracluster = os.path.join(cluster_dir, 'spectra-cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p $GLEAMS_HOME/notebooks/cluster_comparison/spectra-cluster/tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spectra-cluster hyperparameters that influence the clustering quality are:\n",
    "\n",
    "- `-rounds <arg>`: number of clustering rounds to use.\n",
    "- `-threshold_end <arg>`: (lowest) final clustering threshold\n",
    "- `-threshold_start <arg>`: (highest) starting threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_spectracluster = list(itertools.product(\n",
    "    [0.9999, 0.999, 0.99, 0.95, 0.9, 0.8, 0.7], [3, 5, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (threshold_end, rounds) in enumerate(hp_spectracluster):\n",
    "    logger.info('spectra-cluster run %d (threshold_end=%.2f ; rounds=%d)',\n",
    "                i + 1, threshold_end, rounds)\n",
    "    # Execute clustering.\n",
    "    cmd = f\"\"\"java -jar $GLEAMS_HOME/bin/spectra-cluster/spectra-cluster-cli-1.1.2.jar \\\n",
    "        {cluster_dir}/cluster_comparison.mgf \\\n",
    "        -binary_directory {dir_spectracluster}/tmp \\\n",
    "        -fragment_tolerance 0.05 \\\n",
    "        -keep_binary_files \\\n",
    "        -major_peak_jobs $(nproc --all) \\\n",
    "        -output_path {dir_spectracluster}/clusters_{i}.txt \\\n",
    "        -precursor_tolerance 10 \\\n",
    "        -precursor_tolerance_unit ppm \\\n",
    "        -reuse_binary_files \\\n",
    "        -rounds {rounds} \\\n",
    "        -threshold_end {threshold_end} \\\n",
    "        -threshold_start 1.0 \\\n",
    "        -x_disable_mgf_comments\"\"\"\n",
    "    start_time = time.time()\n",
    "    if not os.path.isfile(os.path.join(dir_spectracluster,\n",
    "                                       f'clusters_{i}.txt')):\n",
    "        ! eval {cmd}\n",
    "        timing['spectra-cluster'].append(time.time() - start_time)\n",
    "    else:\n",
    "        timing['spectra-cluster'].append(np.nan)\n",
    "    # Evaluate clustering performance.\n",
    "    cluster_labels, cluster_i = np.full(len(metadata), -1), -1\n",
    "    with open(os.path.join(dir_spectracluster, f'clusters_{i}.txt')) as f_in:\n",
    "        for line in f_in:\n",
    "            if line.startswith('=Cluster='):\n",
    "                cluster_i += 1\n",
    "            elif line.startswith('SPEC'):\n",
    "                cluster_labels[\n",
    "                    int(line[line.find('#id=index=') + len('#id=index='):\n",
    "                             line.find('#title')]) - 1] = cluster_i\n",
    "    performance['spectra-cluster'].append(\n",
    "        evaluate_clusters(pd.DataFrame({'sequence': metadata['sequence'],\n",
    "                                        'cluster': cluster_labels}).dropna(),\n",
    "                          min_cluster_size, min_peptide_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLEAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_gleams = os.path.join(cluster_dir, 'gleams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p $GLEAMS_HOME/notebooks/cluster_comparison/gleams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the relevant entries from all (previously computed) embeddings.\n",
    "embed_idx = (\n",
    "    pd.merge(metadata, (pd.read_parquet(\n",
    "        os.path.join(os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "                     f'embed_{config.massivekb_task_id}_{split}.parquet'))\n",
    "                            .reset_index()),\n",
    "             'right', ['dataset', 'filename', 'scan'])\n",
    "    ['index'].astype(np.int64))\n",
    "metadata_gleams = metadata.loc[embed_idx.index]\n",
    "embeddings = np.load(\n",
    "    os.path.join(os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "                 f'embed_{config.massivekb_task_id}_{split}.npy'),\n",
    "    mmap_mode='r')[embed_idx.values]\n",
    "np.save(os.path.join(dir_gleams, 'embed_cluster_comparison.npy'), embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise distances.\n",
    "if (not os.path.isfile(os.path.join(\n",
    "        dir_gleams, 'dist_cluster_comparison.npz'))):\n",
    "    cluster.compute_pairwise_distances(\n",
    "        os.path.join(dir_gleams, 'embed_cluster_comparison.npy'),\n",
    "        filename_metadata)\n",
    "    os.rename(os.path.join(os.environ['GLEAMS_HOME'], 'data', 'cluster',\n",
    "                           'dist_cluster_comparison.npz'),\n",
    "              os.path.join(dir_gleams, 'dist_cluster_comparison.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters_mz_diff(clusters, min_cluster_size, min_peptide_size):\n",
    "    # Ignore small clusters.\n",
    "    if min_cluster_size is not None:\n",
    "        cluster_counts = clusters['cluster'].value_counts()\n",
    "        clusters.loc[clusters['cluster'].isin(cluster_counts[\n",
    "            cluster_counts < min_cluster_size].index), 'cluster'] = -1\n",
    "    # Only expect frequently occuring peptides to be clustered.\n",
    "    if min_peptide_size is not None:\n",
    "        peptide_counts = clusters['sequence'].value_counts()\n",
    "        clusters = clusters[clusters['sequence'].isin(\n",
    "            peptide_counts[peptide_counts >= min_peptide_size].index)]\n",
    "    clusters_non_noise = clusters[clusters['cluster'] != -1]\n",
    "    \n",
    "    def _get_cluster_mz_diff(cluster):\n",
    "        cluster_label = cluster['sequence'].mode().iat[0]\n",
    "        incorrect_i = np.where(cluster['sequence'] != cluster_label)[0]\n",
    "        if len(incorrect_i) > 0:\n",
    "            cluster_mz = (cluster[cluster['sequence'] == cluster_label]\n",
    "                          ['mz'].mean())\n",
    "            return cluster.iloc[incorrect_i]['mz'] - cluster_mz\n",
    "    \n",
    "    mz_diff = (clusters_non_noise.groupby('cluster')\n",
    "               .apply(_get_cluster_mz_diff).values)\n",
    "    return mz_diff[~np.isnan(mz_diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_gleams = list(itertools.product(np.arange(0.25, 0.5, 0.01), [2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_filename = os.path.join(\n",
    "    dir_gleams, 'clusters_cluster_comparison.npy')\n",
    "for i, (eps, min_samples) in enumerate(hp_gleams):\n",
    "    logger.info('GLEAMS run %d (eps=%.4f ; min_samples=%d)',\n",
    "                i + 1, eps, min_samples)\n",
    "    if os.path.isfile(cluster_filename):\n",
    "        os.remove(cluster_filename)\n",
    "    config.eps, config.min_samples = eps, min_samples\n",
    "    # Execute clustering.\n",
    "    start_time = time.time()\n",
    "    cluster.cluster(os.path.join(dir_gleams, 'dist_cluster_comparison.npz'))\n",
    "    timing['GLEAMS'].append(time.time() - start_time)\n",
    "    # Evaluate clustering performance.\n",
    "    performance['GLEAMS'].append(\n",
    "        evaluate_clusters(\n",
    "            pd.DataFrame({'sequence': metadata_gleams['sequence'],\n",
    "                          'cluster': np.load(cluster_filename)}).dropna(),\n",
    "            min_cluster_size, min_peptide_size))\n",
    "    clusters_mz_diff = get_clusters_mz_diff(\n",
    "        pd.DataFrame({'sequence': metadata_gleams['sequence'],\n",
    "                      'cluster': np.load(cluster_filename),\n",
    "                      'mz': metadata_gleams['mz']}),\n",
    "        min_cluster_size, min_peptide_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pareto_frontier(arr, threshold0=0, threshold1=0):\n",
    "    # Sort by the first column.\n",
    "    arr_sorted = arr[arr[:, 0].argsort()]\n",
    "    # Iteratively add points to the Pareto frontier.\n",
    "    pareto_idx = [0]\n",
    "    for i in range(1, arr_sorted.shape[0]):\n",
    "        if (arr_sorted[i, 0] > (arr_sorted[pareto_idx[-1], 0]\n",
    "                                + threshold0) and\n",
    "                arr_sorted[i, 1] > (arr_sorted[pareto_idx[-1], 1]\n",
    "                                    + threshold1)):\n",
    "            pareto_idx.append(i)\n",
    "    return arr_sorted[pareto_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump((performance, timing), 'cluster_comparison.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance, timing = joblib.load('cluster_comparison.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "for tool, values in performance.items():\n",
    "    pareto = get_pareto_frontier(np.asarray(values)[:, [1, 0]],\n",
    "                                 0.001, 0.01)\n",
    "    ax.plot(pareto[:, 0], pareto[:, 1], marker='o', label=tool)\n",
    "\n",
    "ax.set_xlim(0, 0.05)\n",
    "ax.set_ylim(0.45, 1)\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "ax.set_xlabel('Incorrectly clustered spectra')\n",
    "ax.set_ylabel('Clustered spectra')\n",
    "\n",
    "ax.xaxis.set_major_formatter(mticker.PercentFormatter(1))\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(1))\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('cluster_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
