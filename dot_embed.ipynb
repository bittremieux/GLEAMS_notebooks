{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['GLEAMS_HOME'] = os.path.join(\n",
    "    os.environ['HOME'], 'Projects', 'gleams')\n",
    "# Make sure all code is in the PATH.\n",
    "src_dir = os.path.normpath(os.path.join(os.environ['GLEAMS_HOME'], 'src'))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import math\n",
    "from typing import Iterator, List, Tuple\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.spatial.distance as ssd\n",
    "import seaborn as sns\n",
    "import tqdm.notebook as tqdm\n",
    "from spectrum_utils import utils as suu\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging.\n",
    "from gleams import logger as glogger\n",
    "glogger.init()\n",
    "# Initialize all random seeds before importing any packages.\n",
    "from gleams import rndm\n",
    "rndm.set_seeds()\n",
    "\n",
    "from gleams import config\n",
    "from gleams.feature import spectrum\n",
    "from gleams.metadata import metadata\n",
    "from gleams.ms_io import ms_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('gleams')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styling.\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='serif')\n",
    "sns.set_palette('Set1')\n",
    "sns.set_context('paper', font_scale=1.3)    # Single-column figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def generate_pairs_unknown(metadata_filename: str,\n",
    "                           mz_tolerance: float) -> None:\n",
    "    \"\"\"\n",
    "    Generate index pairs for unknown pairs for the given metadata file.\n",
    "\n",
    "    The unknown pairs consist of all pairs with a precursor m/z difference\n",
    "    smaller than the given m/z tolerance, and for which at least one spectrum\n",
    "    is not identified.\n",
    "    Pairs of row numbers in the metadata file for each unknown pair are stored\n",
    "    in Parquet file `{metadata_filename}_pairs_unknown.parquet`.\n",
    "    If this file already exists it will _not_ be recreated.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metadata_filename_ident : str\n",
    "        The metadata file name containing information for the identified\n",
    "        spectra. Should be a Parquet file.\n",
    "    metadata_filename : str\n",
    "        The metadata file name containing information for all spectra. Should\n",
    "        be a Parquet file.\n",
    "    mz_tolerance : float\n",
    "        Maximum precursor m/z tolerance in ppm for two spectra to be\n",
    "        considered an unknown pair.\n",
    "    \"\"\"\n",
    "    pairs_filename = metadata_filename.replace('.parquet', '_pairs_unk.npy')\n",
    "    if not os.path.isfile(pairs_filename):\n",
    "        logger.info('Generate unknown pair indexes for metadata file %s',\n",
    "                    metadata_filename)\n",
    "        metadata = (pd.read_parquet(metadata_filename,\n",
    "                                    columns=['sequence', 'charge', 'mz'])\n",
    "                    .reset_index())\n",
    "        metadata = (metadata.sort_values(['charge', 'mz'])\n",
    "                    .reset_index(drop=True))\n",
    "        row_nums = metadata['index'].values\n",
    "        mzs = metadata['mz'].values\n",
    "        # List because Numba can't handle object (string) arrays.\n",
    "        sequences = nb.typed.List(metadata['sequence'].fillna('unknown'))\n",
    "        logger.debug('Save unknown pair indexes to %s', pairs_filename)\n",
    "        np.save(pairs_filename,\n",
    "                np.fromiter(\n",
    "                    _generate_pairs_unknown(row_nums, mzs, sequences,\n",
    "                                            mz_tolerance),\n",
    "                    np.uint32).reshape((-1, 2)))\n",
    "\n",
    "\n",
    "@nb.njit\n",
    "def _generate_pairs_unknown(\n",
    "    row_nums: np.ndarray, mzs: np.ndarray, sequences: nb.typed.List,\n",
    "    precursor_mz_tol: float) -> Iterator[int]:\n",
    "    \"\"\"\n",
    "    Numba utility function to efficiently generate row numbers for unknown\n",
    "    pairs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row_nums : np.ndarray\n",
    "        A NumPy array of row numbers for each spectrum.\n",
    "    mzs : np.ndarray\n",
    "        A NumPy array of precursor m/z values for each spectrum.\n",
    "    sequences : nb.typed.List\n",
    "        A list of peptide sequences for each spectrum.\n",
    "    precursor_mz_tol : float\n",
    "        Maximum precursor m/z tolerance in ppm for two PSMs to be considered\n",
    "        a negative pair.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Iterator[int]\n",
    "        A generator of row numbers for the spectrum pairs, with row numbers\n",
    "        `i` and `i + 1` forming pairs.\n",
    "    \"\"\"\n",
    "    for row_num1 in range(len(row_nums)):\n",
    "        row_num2 = row_num1 + 1\n",
    "        while (row_num2 < len(mzs) and\n",
    "               (abs(suu.mass_diff(mzs[row_num1], mzs[row_num2], False))\n",
    "                <= precursor_mz_tol)):\n",
    "            if (sequences[row_num1] == 'unknown'\n",
    "                    or sequences[row_num2] == 'unknown'):\n",
    "                yield row_nums[row_num1]\n",
    "                yield row_nums[row_num2]\n",
    "            row_num2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class PairIndexSequence(Sequence):\n",
    "\n",
    "    def __init__(self, filename_pairs_pos: str, filename_pairs_neg: str,\n",
    "                 filename_pairs_unk: str, batch_size: int,\n",
    "                 max_num_pairs: int = None, shuffle: bool = True):\n",
    "        pairs_pos = np.load(filename_pairs_pos, mmap_mode='r')\n",
    "        pairs_neg = np.load(filename_pairs_neg, mmap_mode='r')\n",
    "        pairs_unk = np.load(filename_pairs_unk, mmap_mode='r')\n",
    "        num_pairs = min(len(pairs_pos), len(pairs_neg), len(pairs_unk))\n",
    "        if max_num_pairs is not None:\n",
    "            num_pairs = min(num_pairs, max_num_pairs // 2)\n",
    "        logger.info('Using %d positive, negative, and unknown feature pairs '\n",
    "                    'each', num_pairs)\n",
    "        idx_pos = np.random.choice(pairs_pos.shape[0], num_pairs, False)\n",
    "        self.pairs_pos = pairs_pos[idx_pos]\n",
    "        idx_neg = np.random.choice(pairs_neg.shape[0], num_pairs, False)\n",
    "        self.pairs_neg = pairs_neg[idx_neg]\n",
    "        idx_unkown = np.random.choice(pairs_unk.shape[0], num_pairs, False)\n",
    "        self.pairs_unk = pairs_unk[idx_unkown]\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.epoch_count = 0\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Gives the total number of batches.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of batches.\n",
    "        \"\"\"\n",
    "        return int(math.ceil(3 * len(self.pairs_pos) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[List[np.ndarray], np.ndarray]:\n",
    "        \"\"\"\n",
    "        Get the pair indexes and labels for the batch with the given index.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : int\n",
    "            Index of the requested batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Tuple[np.ndarray], np.ndarray]\n",
    "            A tuple of pair indexes and class labels.\n",
    "            The class labels are 1 for positive pairs, -1 for negative pairs,\n",
    "            and 0 for unknown pairs.\n",
    "        \"\"\"\n",
    "        batch_pairs_pos = self.pairs_pos[idx * self.batch_size // 2:\n",
    "                                         (idx + 1) * self.batch_size // 2]\n",
    "        batch_pairs_neg = self.pairs_neg[idx * self.batch_size // 2:\n",
    "                                         (idx + 1) * self.batch_size // 2]\n",
    "        batch_pairs_unk = self.pairs_unk[idx * self.batch_size // 2:\n",
    "                                         (idx + 1) * self.batch_size // 2]\n",
    "        batch_pairs = np.vstack((batch_pairs_pos, batch_pairs_neg,\n",
    "                                 batch_pairs_unk))\n",
    "\n",
    "        batch_x1 = batch_pairs[:, 0]\n",
    "        batch_x2 = batch_pairs[:, 1]\n",
    "        batch_y = np.hstack((np.ones(len(batch_pairs_pos), np.uint8),\n",
    "                             -1 * np.ones(len(batch_pairs_neg), np.uint8),\n",
    "                             np.zeros(len(batch_pairs_unk), np.uint8)))\n",
    "\n",
    "        return (batch_x1, batch_x2), batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.epoch_count += 1\n",
    "        if self.shuffle and self.epoch_count % len(self) == 0:\n",
    "            logger.debug('Shuffle the features because all pairs have been '\n",
    "                         'processed after epoch %d', self.epoch_count)\n",
    "            np.random.shuffle(self.pairs_pos)\n",
    "            np.random.shuffle(self.pairs_neg)\n",
    "            np.random.shuffle(self.pairs_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def _get_spectra_from_file(dataset, filename, scans):\n",
    "    spectra = {}\n",
    "    filepath = os.path.join(os.environ['GLEAMS_HOME'], 'data', 'peak',\n",
    "                            dataset, filename)\n",
    "    if not os.path.isfile(filepath):\n",
    "        logger.warning('Missing peak file %s, no spectra read', filename)\n",
    "    else:\n",
    "        for spec in ms_io.get_spectra(filepath, scans):\n",
    "            spectra[f'{dataset}/{filename}/{spec.identifier}'] = \\\n",
    "                spectrum.preprocess(spec, config.fragment_mz_min,\n",
    "                                    config.fragment_mz_max)\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True)\n",
    "def dot(spectra_arr1, spectra_arr2, out, fragment_mz_tol):\n",
    "    for i in nb.prange(spectra_arr1.shape[0]):\n",
    "        out[i] = spectrum.dot(\n",
    "            spectra_arr1[i, 0], spectra_arr1[i, 1],\n",
    "            spectra_arr2[i, 0], spectra_arr2[i, 1],\n",
    "            fragment_mz_tol)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'test'\n",
    "num_pairs = 5_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata table for all (identified and unidentified) spectra.   \n",
    "spectrum_info = pd.merge(\n",
    "    pd.read_parquet(os.path.join(\n",
    "        os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "        f'embed_{config.massivekb_task_id}_{split}.parquet')),\n",
    "    pd.read_parquet(os.path.join(\n",
    "        os.environ['GLEAMS_HOME'], 'data', 'feature',\n",
    "        f'feature_{config.massivekb_task_id}_{split}.parquet'))\n",
    "    [['dataset', 'filename', 'scan', 'sequence']],\n",
    "    'left', ['dataset', 'filename', 'scan'], copy=False)\n",
    "spectrum_info.to_parquet('dot_embed_metadata.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all types of pairs (positive, negative, unknown).\n",
    "metadata.generate_pairs_positive('dot_embed_metadata.parquet')\n",
    "metadata.generate_pairs_negative(\n",
    "    'dot_embed_metadata.parquet', config.pair_mz_tolerance,\n",
    "    config.negative_pair_fragment_tolerance,\n",
    "    config.negative_pair_matching_fragments_threshold)\n",
    "generate_pairs_unknown(\n",
    "    'dot_embed_metadata.parquet', config.pair_mz_tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_generator = PairIndexSequence(\n",
    "    'dot_embed_metadata_pairs_pos.npy', 'dot_embed_metadata_pairs_neg.npy',\n",
    "    'dot_embed_metadata_pairs_unk.npy', config.batch_size, num_pairs, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the spectrum info to only include the selected spectra from the pair\n",
    "# generator.\n",
    "spectrum_indexes = np.hstack((pair_generator.pairs_pos.reshape((-1)),\n",
    "                              pair_generator.pairs_neg.reshape((-1)),\n",
    "                              pair_generator.pairs_unk.reshape((-1))))\n",
    "spectrum_info = spectrum_info.loc[np.unique(spectrum_indexes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the selected spectra from the peak files.\n",
    "dataset_total = spectrum_info['dataset'].nunique()\n",
    "spectra = []\n",
    "for dataset_i, (dataset, md_dataset) in enumerate(\n",
    "        spectrum_info.groupby('dataset', sort=False), 1):\n",
    "    logging.info('Process dataset %s (%d files) [%3d/%3d]', dataset,\n",
    "                 md_dataset['filename'].nunique(), dataset_i, dataset_total)\n",
    "    spectra.extend(joblib.Parallel(n_jobs=-1, backend='multiprocessing')(\n",
    "        joblib.delayed(_get_spectra_from_file)(dataset, filename,\n",
    "                                               md_file['scan'])\n",
    "        for filename, md_file in md_dataset.groupby(\n",
    "            'filename', sort=False)))\n",
    "spectra = collections.ChainMap(*spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the dot products (high/low resolution) between all spectra pairs.\n",
    "spectra_arr = [], []\n",
    "for batch_i in tqdm.tqdm(range(len(pair_generator)),\n",
    "                         desc='Spectra converted', unit='batch'):\n",
    "    (batch_i1, batch_i2), _ = pair_generator[batch_i]\n",
    "    for pair_i, arr_i in zip(itertools.chain(batch_i1, batch_i2),\n",
    "                             np.hstack((np.zeros_like(batch_i1),\n",
    "                                        np.ones_like(batch_i2)))):\n",
    "        spec = spectra[f\"{spectrum_info.at[pair_i, 'dataset']}/\"\n",
    "                       f\"{spectrum_info.at[pair_i, 'filename']}/\"\n",
    "                       f\"{spectrum_info.at[pair_i, 'scan']}\"]\n",
    "        spectra_arr[arr_i].append(\n",
    "            np.pad([spec.mz, spec.intensity],\n",
    "                   ((0, 0), (config.max_peaks_used - len(spec.mz), 0)),\n",
    "                   'constant'))\n",
    "\n",
    "fragment_mz_tol_high_res, fragment_mz_tol_low_res = 0.05, 0.8\n",
    "spectra_arr1 = np.asarray(spectra_arr[0])\n",
    "spectra_arr2 = np.asarray(spectra_arr[1])\n",
    "logger.info('Compute dot product (high resolution; '\n",
    "            'fragment m/z tolerance = %.2f)', fragment_mz_tol_high_res)\n",
    "dot_high_res = dot(\n",
    "    spectra_arr1, spectra_arr2, np.zeros(spectra_arr1.shape[0], np.float32),\n",
    "    fragment_mz_tol_high_res)\n",
    "logger.info('Compute dot product (low resolution; '\n",
    "            'fragment m/z tolerance = %.2f)', fragment_mz_tol_low_res)\n",
    "dot_low_res = dot(\n",
    "    spectra_arr1, spectra_arr2, np.zeros(spectra_arr1.shape[0], np.float32),\n",
    "    fragment_mz_tol_low_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLEAMS Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Euclidean distances between all embeddings pairs.\n",
    "embeddings = np.load(os.path.join(\n",
    "    os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "    f'embed_{config.massivekb_task_id}_{split}.npy'))\n",
    "\n",
    "scores_embed = []\n",
    "for batch_i in tqdm.tqdm(range(len(pair_generator)),\n",
    "                         desc='GLEAMS distances calculated', unit='batch'):\n",
    "    (batch_i1, batch_i2), _ = pair_generator[batch_i]\n",
    "    for pair1, pair2 in zip(batch_i1, batch_i2):\n",
    "        scores_embed.append(ssd.euclidean(embeddings[pair1],\n",
    "                                          embeddings[pair2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product versus GLEAMS Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.hstack([pair_generator[batch_i][1]\n",
    "                    for batch_i in range(len(pair_generator))])\n",
    "dot_embed = pd.DataFrame({'dot_low_res': dot_low_res,\n",
    "                          'dot_high_res': dot_high_res,\n",
    "                          'gleams_dist': scores_embed,\n",
    "                          'pair_type': labels}).sort_values('pair_type')\n",
    "# Convert pair type to nice labels.\n",
    "dot_embed['pair_type'] = dot_embed['pair_type'].map(\n",
    "    {1: 'Positive', -1: 'Negative', 0: 'Unknown'})\n",
    "# Add precursor information.\n",
    "spec_idx = np.hstack([pair_generator[batch_i][0][0]\n",
    "                      for batch_i in range(len(pair_generator))])\n",
    "dot_embed[['charge', 'mz']] = (spectrum_info.loc[spec_idx, ['charge', 'mz']]\n",
    "                               .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_embed.to_parquet('dot_embed.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_embed = pd.read_parquet('aucroc_dot.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "\n",
    "jg = sns.jointplot(data=dot_embed, x='dot_high_res', y='gleams_dist',\n",
    "                   hue='pair_type', palette='Set1', height=width,\n",
    "                   s=1, marker='.', rasterized=True,\n",
    "                   joint_kws={'alpha': 0.1})\n",
    "\n",
    "jg.ax_joint.legend(jg.ax_joint.get_legend_handles_labels()[0],\n",
    "                   ['Negative', 'Unknown', 'Positive'], title='Pair type')\n",
    "jg.set_axis_labels('Spectrum dot product', 'GLEAMS euclidean distance')\n",
    "\n",
    "plt.savefig('dot_embed_type.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 7\n",
    "\n",
    "dot_embed_charge = dot_embed[dot_embed['charge'] <= 4]\n",
    "\n",
    "jg = sns.JointGrid(height=height)\n",
    "sns.scatterplot(data=dot_embed_charge, x='dot_high_res', y='gleams_dist',\n",
    "                hue='charge', palette='Set1', alpha=0.1, s=1, marker='.',\n",
    "                rasterized=True, ax=jg.ax_joint)\n",
    "sns.kdeplot(data=dot_embed_charge, x='dot_high_res', hue='charge',\n",
    "            palette='Set1', legend=False, common_norm=False, fill=True,\n",
    "            ax=jg.ax_marg_x)\n",
    "sns.kdeplot(data=dot_embed_charge, y='gleams_dist', hue='charge',\n",
    "            palette='Set1', legend=False, common_norm=False, fill=True,\n",
    "            ax=jg.ax_marg_y)\n",
    "\n",
    "jg.ax_joint.legend(loc='upper right', title='Precursor charge')\n",
    "jg.set_axis_labels('Spectrum dot product', 'Embedded euclidean distance')\n",
    "\n",
    "plt.savefig('dot_embed_charge.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 7\n",
    "\n",
    "jg = sns.JointGrid(height=height)\n",
    "sns.scatterplot(data=dot_embed, x='dot_high_res', y='gleams_dist',\n",
    "                alpha=0.1, s=1, c=dot_embed['mz'], marker='.',\n",
    "                cmap=plt.cm.get_cmap('YlGnBu'), rasterized=True,\n",
    "                ax=jg.ax_joint)\n",
    "sns.kdeplot(data=dot_embed, x='dot_high_res', color='black', legend=False,\n",
    "            common_norm=False, fill=True, ax=jg.ax_marg_x)\n",
    "sns.kdeplot(data=dot_embed, y='gleams_dist', color='black', legend=False,\n",
    "            common_norm=False, fill=True, ax=jg.ax_marg_y)\n",
    "\n",
    "ax_joint_pos = jg.ax_joint.get_position()\n",
    "cbar_ax = jg.fig.add_axes([1.025, ax_joint_pos.x0 + 0.05,\n",
    "                           0.025, ax_joint_pos.height - 0.1])\n",
    "colorbar = jg.fig.colorbar(jg.ax_joint.get_children()[0], cax=cbar_ax)\n",
    "colorbar.solids.set(alpha=1)\n",
    "colorbar.set_label('Precursor m/z', size='large', labelpad=15)\n",
    "\n",
    "jg.set_axis_labels('Spectrum dot product', 'Embedded euclidean distance')\n",
    "\n",
    "plt.savefig('dot_embed_mz.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
