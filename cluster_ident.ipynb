{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['GLEAMS_HOME'] = os.path.join(os.environ['HOME'],\n",
    "                                         'Projects/gleams')\n",
    "# Make sure all code is in the PATH.\n",
    "sys.path.append(\n",
    "    os.path.normpath(os.path.join(os.environ['GLEAMS_HOME'], 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyteomics\n",
    "import seaborn as sns\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "from evaluate_clusters import evaluate_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging.\n",
    "from gleams import logger as glogger\n",
    "glogger.init()\n",
    "# Initialize all random seeds before importing any packages.\n",
    "from gleams import rndm\n",
    "rndm.set_seeds()\n",
    "\n",
    "from gleams import config\n",
    "from gleams.cluster import cluster\n",
    "from gleams.metadata.metadata import _remove_mod\n",
    "from gleams.ms_io import ms_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('gleams')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styling.\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='serif')\n",
    "sns.set_palette(['#9e0059', '#6da7de', '#ee266d', '#dee000', '#eb861e'])\n",
    "sns.set_context('paper', font_scale=1.3)    # Single-column figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Cluster the spectra (using the previously determined optimal clustering hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(os.path.join(os.environ['GLEAMS_HOME'], 'data', 'cluster',\n",
    "                           f'clusters_{config.massivekb_task_id}.npy'))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "cluster.compute_pairwise_distances(\n",
    "    os.path.join(os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "                 f'embed_{config.massivekb_task_id}.npy'),\n",
    "    os.path.join(os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "                 f'embed_{config.massivekb_task_id}.parquet'),\n",
    "    config.charges)\n",
    "cluster.cluster(os.path.join(os.environ['GLEAMS_HOME'], 'data', 'cluster',\n",
    "                             f'dist_{config.massivekb_task_id}.npz'),\n",
    "                os.path.join(os.environ['GLEAMS_HOME'], 'data', 'cluster',\n",
    "                             f'embed_{config.massivekb_task_id}.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.merge(\n",
    "    pd.read_parquet(\n",
    "        os.path.join(os.environ['GLEAMS_HOME'], 'data', 'cluster',\n",
    "                     f'embed_{config.massivekb_task_id}.parquet'))\n",
    "    [['dataset', 'filename', 'scan', 'charge', 'mz']],\n",
    "    (pd.read_parquet(\n",
    "        os.path.join(os.environ['GLEAMS_HOME'], 'data', 'metadata',\n",
    "                     f'massivekb_ids_{config.massivekb_task_id}.parquet'))\n",
    "     [['dataset', 'filename', 'scan', 'sequence']]),\n",
    "    'left', ['dataset', 'filename', 'scan'])\n",
    "# Don't disambiguate between I/L.\n",
    "clusters['sequence'] = clusters['sequence'].str.replace('I', 'L')\n",
    "clusters['cluster'] = np.load(os.path.join(\n",
    "    os.environ['GLEAMS_HOME'], 'data', 'cluster',\n",
    "    f'clusters_{config.massivekb_task_id}.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_id_massive = clusters['sequence'].count()\n",
    "print(f'Number of initial spectrum identifications: {num_id_massive:,} '\n",
    "      f'({(num_id_massive / len(clusters)):.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering performance (excluding modifications).\n",
    "num_clustered, num_noise, \\\n",
    "    prop_clustered, prop_clustered_incorrect, \\\n",
    "    homogeneity, completeness = evaluate_clusters(\n",
    "        pd.DataFrame(\n",
    "            {'sequence': (clusters['sequence'].apply(\n",
    "                              lambda seq: (_remove_mod(seq)\n",
    "                                           if pd.notnull(seq)\n",
    "                                           else np.nan))\n",
    "                          + '/' + clusters['charge'].astype(str)),\n",
    "                      'cluster': clusters['cluster']}),\n",
    "        min_cluster_size)\n",
    "num_clustered = len(clusters[clusters[\"cluster\"] != -1])\n",
    "print(f'Number of clustered spectra: {num_clustered:,} / {len(clusters):,} '\n",
    "      f'({num_clustered / len(clusters):.2%})')\n",
    "print(f'Incorrectly clustered spectra: {prop_clustered_incorrect:.2%}')\n",
    "print(f'Clustering homogeneity: {homogeneity:.3f}')\n",
    "print(f'Clustering completeness: {completeness:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum export\n",
    "\n",
    "Export the unidentified spectra that are part of valid clusters to MGF files used for reidentification. Spectra clustered as noise are not exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_usis(df):\n",
    "    return ('mzspec:' + df['dataset'] + ':' +\n",
    "            df['filename'].apply(\n",
    "                lambda fn: os.path.splitext(os.path.basename(fn))[0]) +\n",
    "            ':scan:' + df['scan'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_medoids = os.path.join(\n",
    "    os.environ['GLEAMS_HOME'], 'data', 'cluster',\n",
    "    f'clusters_{config.massivekb_task_id}_medoids.npy')\n",
    "if not os.path.isfile(filename_medoids):\n",
    "    cluster_i_medoid = cluster.get_cluster_medoids(\n",
    "        os.path.join(os.environ['GLEAMS_HOME'], 'data', 'cluster',\n",
    "                     f'clusters_{config.massivekb_task_id}.npy'),\n",
    "        os.path.join(os.environ['GLEAMS_HOME'], 'data', 'cluster',\n",
    "                     f'dist_{config.massivekb_task_id}.npz'))\n",
    "    np.save(filename_medoids, cluster_i_medoid)\n",
    "else:\n",
    "    cluster_i_medoid = np.load(filename_medoids)\n",
    "cluster_i_non_ident = (clusters.groupby('cluster')['sequence']\n",
    "                       .apply(lambda sequences: all(pd.isnull(sequences))))\n",
    "cluster_i_non_ident = cluster_i_non_ident[cluster_i_non_ident].index\n",
    "cluster_medoids = clusters.iloc[cluster_i_medoid]\n",
    "cluster_medoids_non_ident = cluster_medoids[cluster_medoids['cluster']\n",
    "                                            .isin(cluster_i_non_ident)]\n",
    "cluster_medoids_non_ident = pd.merge(\n",
    "    cluster_medoids_non_ident,\n",
    "    clusters['cluster'].value_counts().rename('cluster_size'),\n",
    "    'left', left_on='cluster', right_index=True)\n",
    "dataset_filename_scans = (cluster_medoids_non_ident\n",
    "                          .groupby(['dataset', 'filename'])['scan']\n",
    "                          .apply(sorted).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_non_ident = len(clusters[clusters['cluster'].isin(\n",
    "    cluster_medoids_non_ident['cluster'])])\n",
    "print(f'Number of clustered, unidentified spectra: {clusters_non_ident:,} '\n",
    "      f'({(clusters_non_ident / len(clusters)):.2%})')\n",
    "num_export = dataset_filename_scans['scan'].apply(len).sum()\n",
    "print(f'Number of unidentified cluster medoids: '\n",
    "      f'{len(cluster_medoids_non_ident):,} '\n",
    "      f'({(len(cluster_medoids_non_ident) / len(clusters)):.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reident_peak_dir = os.path.join('cluster_ident', 'peak')\n",
    "os.makedirs(reident_peak_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectra_from_file(dataset: str, filename: str, scans: List[int]):\n",
    "    filename_base = os.path.splitext(os.path.basename(filename))[0]\n",
    "    filename_orig = os.path.join(os.environ['GLEAMS_HOME'], 'data', 'peak',\n",
    "                                 dataset, filename)\n",
    "    filename_tmp = os.path.join('/tmp', filename)\n",
    "    ! cp {filename_orig} /tmp\n",
    "    scans = set(scans)\n",
    "    for spec in ms_io.get_spectra(filename_tmp):\n",
    "        if int(spec.identifier) in scans:\n",
    "            usi = f'mzspec:{dataset}:{filename_base}:scan:{spec.identifier}'\n",
    "            yield (usi, {'m/z array': spec.mz,\n",
    "                         'intensity array': spec.intensity,\n",
    "                         'params': {'TITLE': usi,\n",
    "                                    'RTINSECONDS': spec.retention_time,\n",
    "                                    'PEPMASS': spec.precursor_mz,\n",
    "                                    'CHARGE': f'{spec.precursor_charge}+'}})\n",
    "            scans.remove(int(spec.identifier))\n",
    "            if len(scans) == 0:\n",
    "                break\n",
    "    ! rm {filename_tmp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Read and export cluster medoid spectra to MGF files in '\n",
    "            'directory %s', reident_peak_dir)\n",
    "spectra_dicts = {}\n",
    "with tqdm.tqdm(total=sum(dataset_filename_scans['scan'].apply(len)),\n",
    "               unit='spectra') as pbar:\n",
    "    for dataset, filename, scans in zip(dataset_filename_scans['dataset'],\n",
    "                                        dataset_filename_scans['filename'],\n",
    "                                        dataset_filename_scans['scan']):\n",
    "        for usi, spec in get_spectra_from_file(dataset, filename, scans):\n",
    "            spectra_dicts[usi] = spec\n",
    "            pbar.update(1)\n",
    "# Clusters of size 2.\n",
    "pyteomics.mgf.write(\n",
    "    [spectra_dicts[usi] for usi in _get_usis(\n",
    "        cluster_medoids_non_ident[cluster_medoids_non_ident['cluster_size'] == 2])],\n",
    "    os.path.join(reident_peak_dir, 'cluster_ident_2.mgf'), use_numpy=True)\n",
    "# Clusters of size larger than 2.\n",
    "pyteomics.mgf.write(\n",
    "    [spectra_dicts[usi] for usi in _get_usis(\n",
    "        cluster_medoids_non_ident[cluster_medoids_non_ident['cluster_size'] > 2])],\n",
    "    os.path.join(reident_peak_dir, 'cluster_ident_n.mgf'), use_numpy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate ANN-SoLo identifications\n",
    "\n",
    "Include the identifications from ANN-SoLo processing of the previously exported unidentified spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mztab_psms(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read PSMs from the given mzTab file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: str\n",
    "        The mzTab file name from which to read the PSMs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A data frame containing the PSM information from the mzTab file.\n",
    "    \"\"\"\n",
    "    # Skip the header lines.\n",
    "    skiplines = 0\n",
    "    with open(filename) as f_in:\n",
    "        line = next(f_in)\n",
    "        while line.split('\\t', 1)[0] != 'PSH':\n",
    "            line = next(f_in)\n",
    "            skiplines += 1\n",
    "    return pd.read_csv(filename, sep='\\t', header=skiplines,\n",
    "                       index_col='PSM_ID').drop(columns='PSH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reident_id_dir = os.path.join('cluster_ident', 'id')\n",
    "psms = pd.concat([read_mztab_psms(os.path.join(reident_id_dir, filename))\n",
    "                  for filename in os.listdir(reident_id_dir)\n",
    "                  if os.path.splitext(filename)[1] == '.mztab'])\n",
    "psms['sequence'] = psms['sequence'].str.replace('I', 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_id_ann_solo = len(psms)\n",
    "print(f'Number of ANN-SoLo spectrum identifications: {num_id_ann_solo:,} '\n",
    "      f'({(num_id_ann_solo / num_export):.2%} of previously unidentified '\n",
    "      f'cluster medoid spectra)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusters.set_index(_get_usis(clusters))\n",
    "clusters.loc[psms.index, 'sequence'] = psms['sequence']\n",
    "clusters['ann_solo'] = False\n",
    "clusters.loc[psms.index, 'ann_solo'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass difference histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_groups(psms, tol_mass, tol_mode, min_group_size=None):\n",
    "    psms_remaining = psms.sort_values('search_engine_score[1]',\n",
    "                                      ascending=False)\n",
    "    psms_remaining['mass_diff'] = ((psms_remaining['exp_mass_to_charge'] -\n",
    "                                    psms_remaining['calc_mass_to_charge']) *\n",
    "                                   psms_remaining['charge'])\n",
    "\n",
    "    # Start with the highest ranked SSM.\n",
    "    mass_groups = []\n",
    "    while psms_remaining.size > 0:\n",
    "        # Find all remaining PSMs within the mass difference window.\n",
    "        mass_diff = psms_remaining['mass_diff'].iat[0]\n",
    "        if (tol_mass is None or tol_mode not in ('Da', 'ppm') or\n",
    "                min_group_size is None):\n",
    "            mask = np.full(len(psms_remaining), True, dtype=bool)\n",
    "        elif tol_mode == 'Da':\n",
    "            mask = (np.fabs(psms_remaining['mass_diff'] - mass_diff) <=\n",
    "                    tol_mass)\n",
    "        elif tol_mode == 'ppm':\n",
    "            mask = (np.fabs(psms_remaining['mass_diff'] - mass_diffs) /\n",
    "                    psms_remaining['exp_mass_to_charge'] * 10 ** 6\n",
    "                    <= tol_mass)\n",
    "        mass_groups.append(psms_remaining[mask])\n",
    "        # Exclude the selected PSMs from further selections.\n",
    "        psms_remaining = psms_remaining[~mask]\n",
    "\n",
    "    mass_group_stats = []\n",
    "    for mass_group in mass_groups:\n",
    "        mass_group_stats.append((mass_group['mass_diff'].median(),\n",
    "                                 mass_group['mass_diff'].mean(),\n",
    "                                 len(mass_group)))\n",
    "    mass_group_stats = pd.DataFrame.from_records(\n",
    "        mass_group_stats, columns=['mass_diff_median', 'mass_diff_mean',\n",
    "                                   'num_psms'])\n",
    "    return mass_group_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_mass, tol_mode, min_group_size = 0.1, 'Da', 20\n",
    "mass_groups = get_mass_groups(psms, tol_mass, tol_mode, min_group_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_groups.sort_values('num_psms', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagate identifications\n",
    "\n",
    "We can propagate identifications within clusters by assigning unmodified spectra the same peptide sequence as the majority of identified spectra in the same cluster.\n",
    "\n",
    "We check both identification propagations based on the initial identifications and additional identification propagations based on the new ANN-SoLo identifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_cluster_num_id_propagation(sequences):\n",
    "    num_ids = pd.notnull(sequences).sum()\n",
    "    return len(sequences) - num_ids if num_ids > 0 else 0\n",
    "\n",
    "\n",
    "def _get_num_id_propagation(clusters):\n",
    "    return clusters.groupby('cluster')['sequence'].apply(\n",
    "        _get_cluster_num_id_propagation).sum()\n",
    "\n",
    "\n",
    "num_id_prop_initial = _get_num_id_propagation(\n",
    "    clusters[(clusters['cluster'] != -1) & ~clusters['ann_solo']])\n",
    "num_id_prop_ann_solo = _get_num_id_propagation(\n",
    "    clusters[clusters['cluster'] != -1]) - num_id_prop_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_id_prop_initial_clusters = clusters.loc[\n",
    "    (clusters['cluster'] != -1) & ~clusters['ann_solo'], 'cluster'].nunique()\n",
    "print(f'Number of initial clusters for propagation: '\n",
    "      f'{num_id_prop_initial_clusters:,}')\n",
    "print(f'Number of propagated initial spectrum identifications: '\n",
    "      f'{num_id_prop_initial:,} '\n",
    "      f'({(num_id_prop_initial / len(clusters)):.2%})')\n",
    "print(f'Number of propagated ANN-SoLo spectrum identifications: '\n",
    "      f'{num_id_prop_ann_solo:,} '\n",
    "      f'({(num_id_prop_ann_solo / len(clusters)):.2%})')\n",
    "num_new_id = num_id_prop_initial + num_id_ann_solo + num_id_prop_ann_solo\n",
    "print(f'Total number of new PSMs: {num_new_id:,} '\n",
    "      f'({num_new_id / len(clusters):.2%})')\n",
    "print(f'PSM increase: {(num_new_id / num_id_massive):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clustered_unidentified = (clusters[clusters['cluster'] != -1]\n",
    "                              ['sequence'].isna().sum()\n",
    "                              - num_id_prop_initial - num_id_prop_ann_solo)\n",
    "num_ids = pd.DataFrame(\n",
    "    [('MassIVE-KB', num_id_massive),\n",
    "     ('MassIVE-KB\\npropagation', num_id_prop_initial),\n",
    "     ('ANN-SoLo', num_id_ann_solo),\n",
    "     ('ANN-SoLo\\npropagation', num_id_prop_ann_solo),\n",
    "     ('clustered\\nunidentified', num_clustered_unidentified)],\n",
    "    columns=['search_mode', 'num_ids']).set_index('search_mode')\n",
    "num_ids.to_csv('cluster_ident.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618\n",
    "fig, axes = plt.subplots(1, 2, figsize=(width * 2, height),\n",
    "                         gridspec_kw={'width_ratios': [1, 3]})\n",
    "\n",
    "# Identification contributions.\n",
    "ax = axes[0]\n",
    "\n",
    "num_ids.plot.bar(ax=ax, color='#9e0059', legend=False)\n",
    "line = ax.plot(range(len(num_ids)), np.cumsum(num_ids['num_ids']),\n",
    "               marker='o', markersize=8, markeredgecolor='white',\n",
    "               markeredgewidth=1)\n",
    "\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Number of identified spectra')\n",
    "ax.ticklabel_format(axis='y', scilimits=(6, 6))\n",
    "\n",
    "ax.legend(line, ['Cumulative'], loc='upper center',\n",
    "          bbox_to_anchor=(0.5, 1.1))\n",
    "\n",
    "# Mass difference histogram.\n",
    "ax = axes[1]\n",
    "# Exclude unmodified PSMs.\n",
    "mask = ((mass_groups['mass_diff_median'].abs() > tol_mass) &\n",
    "        (mass_groups['mass_diff_median'] > -50) &\n",
    "        (mass_groups['mass_diff_median'] < 100))\n",
    "ax.bar(mass_groups[mask]['mass_diff_median'], mass_groups[mask]['num_psms'],\n",
    "       width=0.4, color='black')\n",
    "\n",
    "# Annotate the most frequent modifications.\n",
    "modifications = [('Glu→His', 0, 310000),          #   8.016319\n",
    "                 ('His→Phe', 10, 260000),         #  10.009502\n",
    "                 ('oxidation', 8, 210000),        #  15.994915\n",
    "                 (None, None, None),\n",
    "                 ('', 0, 210000),                 #   2.015650\n",
    "                 ('Phospho', 0, 210000),          #  79.966331\n",
    "                 (None, None, None),\n",
    "                 ('Carbamidomethyl', 0, 110000),  #  57.021464\n",
    "                 ('Lys→Arg', 0, 110000),          #  28.006148\n",
    "                 (None, None, None),\n",
    "                 (None, None, None),\n",
    "                 (None, None, None),\n",
    "                 (None, None, None),\n",
    "                 (None, None, None),\n",
    "                 ('water loss', 0, 110000)]       # -18.010565\n",
    "for (annot, x, y), mass_group in zip(modifications, mass_groups.sort_values(\n",
    "        'num_psms', ascending=False)[1:].itertuples()):\n",
    "    if annot is not None:\n",
    "        ax.annotate(annot,\n",
    "                    (mass_group.mass_diff_median, mass_group.num_psms + 50),\n",
    "                    (mass_group.mass_diff_median + x, y),\n",
    "                    arrowprops={'arrowstyle': '<-', 'linewidth': 1},\n",
    "                    ha='center')\n",
    "ax.text(-0.5, 210000, 'Pro→Val', ha='center')\n",
    "\n",
    "ax.set_xlim((-50, 100))\n",
    "\n",
    "ax.yaxis.set_major_formatter(mticker.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "ax.set_xlabel('Precursor mass difference (Da)')\n",
    "ax.set_ylabel(f'Number of PSMs')\n",
    "\n",
    "for ax in axes:\n",
    "    sns.despine(ax=ax)\n",
    "    \n",
    "fig.subplots_adjust(wspace=0.25)\n",
    "\n",
    "plt.savefig('cluster_ident.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
