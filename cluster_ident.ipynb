{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['GLEAMS_HOME'] = os.path.join(os.environ['HOME'],\n",
    "                                         'Projects/gleams')\n",
    "# Make sure all code is in the PATH.\n",
    "sys.path.append(\n",
    "    os.path.normpath(os.path.join(os.environ['GLEAMS_HOME'], 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "import joblib\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyteomics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('gleams')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gleams.dag import dag\n",
    "\n",
    "from gleams import config\n",
    "from gleams.ms_io import ms_io\n",
    "from gleams.cluster import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styling.\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='serif')\n",
    "sns.set_palette('Set1')\n",
    "sns.set_context('paper', font_scale=1.3)    # Single-column figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Cluster the spectra (using the previously determined optimal clustering hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.eps = 0.02\n",
    "config.min_samples = 2\n",
    "os.remove(os.path.join(os.environ['GLEAMS_HOME'], 'data', 'ann',\n",
    "                       f'clusters_{config.massivekb_task_id}.npy'))\n",
    "cluster.cluster(os.path.join(os.environ['GLEAMS_HOME'], 'data', 'ann',\n",
    "                             f'dist_{config.massivekb_task_id}.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.merge(\n",
    "    pd.read_parquet(\n",
    "        os.path.join(os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "                     f'embed_{config.massivekb_task_id}.parquet')),\n",
    "    pd.read_parquet(\n",
    "        os.path.join(os.environ['GLEAMS_HOME'], 'data', 'metadata',\n",
    "                     f'metadata_{config.massivekb_task_id}.parquet')),\n",
    "    'left', ['dataset', 'filename', 'scan'])\n",
    "# Don't disambiguate between I/L.\n",
    "clusters['sequence'] = clusters['sequence'].str.replace('I', 'L')\n",
    "clusters['cluster'] = np.load(os.path.join(\n",
    "    os.environ['GLEAMS_HOME'], 'data', 'ann',\n",
    "    f'clusters_{config.massivekb_task_id}.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_id_massive = len(clusters['sequence'].dropna())\n",
    "print(f'Number of initial spectrum identifications: {num_id_massive:,} '\n",
    "      f'({(num_id_massive / len(clusters)):.2%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum export\n",
    "\n",
    "Export the unidentified spectra that are part of valid clusters to MGF files used for reidentification. Spectra belonging to the noise cluster are not exported.\n",
    "\n",
    "We hypothesize the clustered spectra correspond to higher quality spectra that are repeatedly measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reident_peak_dir = os.path.join(os.environ['GLEAMS_HOME'], 'data', 'ann',\n",
    "                                'peak')\n",
    "os.makedirs(reident_peak_dir, exist_ok=True)\n",
    "existing_peak_files = set([os.path.splitext(filename)[0]\n",
    "                           for filename in os.listdir(reident_peak_dir)\n",
    "                           if filename.endswith('.mgf')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_non_ident = (clusters[clusters['cluster'] != -1].groupby('cluster')\n",
    "                      ['sequence'].apply(lambda sequences:\n",
    "                                         all(pd.isnull(sequences))))\n",
    "clusters_non_ident = clusters_non_ident[clusters_non_ident].index\n",
    "dataset_filename_scans = (clusters[clusters['cluster']\n",
    "                                   .isin(clusters_non_ident)]\n",
    "                          .groupby(['dataset', 'filename'])\n",
    "                          ['scan'].apply(list)\n",
    "                          .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unid_export = dataset_filename_scans['scan'].apply(len).sum()\n",
    "print(f'Number of clustered, unidentified spectra: {num_unid_export:,} '\n",
    "      f'({(num_unid_export / len(clusters)):.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectra_from_file(dataset: str, filename: str, scans: List[int]):\n",
    "    logger.debug('Process file %s/%s', dataset, filename)\n",
    "    return list(ms_io.get_spectra(os.path.join(\n",
    "        os.environ['GLEAMS_HOME'], 'data', 'peak', dataset, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Read and export clustered, unidentified spectra to MGF files '\n",
    "            'in directory %s', reident_peak_dir)\n",
    "datasets_to_export = dataset_filename_scans[\n",
    "    ~dataset_filename_scans['dataset'].isin(existing_peak_files)]\n",
    "dataset_total = datasets_to_export['dataset'].nunique()\n",
    "for i, (dataset, filename_scans) in enumerate(\n",
    "        datasets_to_export.groupby('dataset'), 1):\n",
    "    logger.debug('Process dataset %s [%3d/%3d]', dataset, i, dataset_total)\n",
    "    spectra_dicts = []\n",
    "    for filename, spectra in zip(\n",
    "            filename_scans['filename'],\n",
    "            joblib.Parallel(n_jobs=-1, backend='multiprocessing')(\n",
    "                joblib.delayed(get_spectra_from_file)\n",
    "                (dataset, filename, scans)\n",
    "                for filename, scans in zip(filename_scans['filename'],\n",
    "                                           filename_scans['scan']))):\n",
    "        spectra_dicts.extend([\n",
    "            {'m/z array': spectrum.mz,\n",
    "            'intensity array': spectrum.intensity,\n",
    "            'params': {\n",
    "                'TITLE': f'mzspec:{dataset}:' \\\n",
    "                    f'{os.path.splitext(filename)[0]}:' \\\n",
    "                    f'scan:{spectrum.identifier}',\n",
    "                'RTINSECONDS': spectrum.retention_time,\n",
    "                'PEPMASS': spectrum.precursor_mz,\n",
    "                'CHARGE': f'{spectrum.precursor_charge}+'}}\n",
    "            for spectrum in spectra])\n",
    "    with open(os.path.join(reident_peak_dir, f'{dataset}.mgf'), 'w') as f:\n",
    "        pyteomics.mgf.write(spectra_dicts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate ANN-SoLo identifications\n",
    "\n",
    "Include the identifications from ANN-SoLo processing of the previously exported unidentified spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mztab_psms(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read PSMs from the given mzTab file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: str\n",
    "        The mzTab file name from which to read the PSMs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A data frame containing the PSM information from the mzTab file.\n",
    "    \"\"\"\n",
    "    # Skip the header lines.\n",
    "    skiplines = 0\n",
    "    with open(filename) as f_in:\n",
    "        line = next(f_in)\n",
    "        while line.split('\\t', 1)[0] != 'PSH':\n",
    "            line = next(f_in)\n",
    "            skiplines += 1\n",
    "    return pd.read_csv(filename, sep='\\t', header=skiplines,\n",
    "                       index_col='PSM_ID').drop(columns='PSH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reident_id_dir = os.path.join(os.environ['GLEAMS_HOME'], 'data', 'ann', 'id')\n",
    "psms = pd.concat([read_mztab_psms(os.path.join(reident_id_dir, filename))\n",
    "                  for filename in os.listdir(reident_id_dir)\n",
    "                  if os.path.splitext(filename)[1] == '.mztab'])\n",
    "psms['sequence'] = psms['sequence'].str.replace('I', 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_id_ann_solo = len(psms)\n",
    "print(f'Number of ANN-SoLo spectrum identifications: {num_id_ann_solo:,} '\n",
    "      f'({(num_id_ann_solo / len(clusters)):.2%}; '\n",
    "      f'{(num_id_ann_solo / num_unid_export):.2%} of previously unidentified '\n",
    "      f'spectra)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusters.set_index(\n",
    "    'mzspec:' + clusters['dataset'] + ':' +\n",
    "    clusters['filename'].str.rsplit('.', 1, True)[0] + ':scan:' +\n",
    "    clusters['scan'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.loc[psms.index, 'sequence'] = psms['sequence']\n",
    "clusters['ann_solo'] = False\n",
    "clusters.loc[psms.index, 'ann_solo'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass difference histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_groups(psms, tol_mass, tol_mode, min_group_size=None):\n",
    "    psms_remaining = psms.sort_values('search_engine_score[1]',\n",
    "                                      ascending=False)\n",
    "    psms_remaining['mass_diff'] = ((psms_remaining['exp_mass_to_charge'] -\n",
    "                                    psms_remaining['calc_mass_to_charge']) *\n",
    "                                   psms_remaining['charge'])\n",
    "\n",
    "    # Start with the highest ranked SSM.\n",
    "    mass_groups = []\n",
    "    while psms_remaining.size > 0:\n",
    "        # Find all remaining PSMs within the mass difference window.\n",
    "        mass_diff = psms_remaining['mass_diff'].iat[0]\n",
    "        if (tol_mass is None or tol_mode not in ('Da', 'ppm') or\n",
    "                min_group_size is None):\n",
    "            mask = np.full(len(psms_remaining), True, dtype=bool)\n",
    "        elif tol_mode == 'Da':\n",
    "            mask = (np.fabs(psms_remaining['mass_diff'] - mass_diff) <=\n",
    "                    tol_mass)\n",
    "        elif tol_mode == 'ppm':\n",
    "            mask = (np.fabs(psms_remaining['mass_diff'] - mass_diffs) /\n",
    "                    psms_remaining['exp_mass_to_charge'] * 10 ** 6\n",
    "                    <= tol_mass)\n",
    "        mass_groups.append(psms_remaining[mask])\n",
    "        # Exclude the selected PSMs from further selections.\n",
    "        psms_remaining = psms_remaining[~mask]\n",
    "\n",
    "    mass_group_stats = []\n",
    "    for mass_group in mass_groups:\n",
    "        mass_group_stats.append((mass_group['mass_diff'].median(),\n",
    "                                 mass_group['mass_diff'].mean(),\n",
    "                                 len(mass_group)))\n",
    "    mass_group_stats = pd.DataFrame.from_records(\n",
    "        mass_group_stats, columns=['mass_diff_median', 'mass_diff_mean',\n",
    "                                   'num_psms'])\n",
    "    return mass_group_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_mass, tol_mode, min_group_size = 0.1, 'Da', 20\n",
    "mass_groups = get_mass_groups(psms, tol_mass, tol_mode, min_group_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_groups.sort_values('num_psms', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618\n",
    "fig, ax = plt.subplots(figsize=(width * 1.5, height / 1.5))\n",
    "\n",
    "# Exclude unmodified PSMs.\n",
    "mask = mass_groups['mass_diff_median'].abs() > tol_mass\n",
    "ax.bar(mass_groups[mask]['mass_diff_median'], mass_groups[mask]['num_psms'],\n",
    "       width=0.4, color='black')\n",
    "\n",
    "# Annotate the most frequent modifications.\n",
    "modifications = [('oxidation', 0, 14000),\n",
    "                 ('first isotopic peak', -15, 12000),\n",
    "                 ('SILAC\\nlabel', 0, 10000),\n",
    "                 (None, None, None),\n",
    "                 (None, None, None),\n",
    "                 ('dehydration', 0, 5000),\n",
    "                 (None, None, None),\n",
    "                 (None, None, None),\n",
    "                 (None, None, None),\n",
    "                 ('Lys→Arg', 0, 5000),\n",
    "                 ('phosphorylation', 0, 5000),\n",
    "                 (None, None, None),\n",
    "                 (None, None, None),\n",
    "                 (None, None, None),\n",
    "                 (None, None, None),\n",
    "                 ('3 protons to iron', 0, 3500)]\n",
    "for (annot, x, y), mass_group in zip(modifications, mass_groups.sort_values(\n",
    "        'num_psms', ascending=False)[1:].itertuples()):\n",
    "    if annot is not None:\n",
    "        ax.annotate(annot,\n",
    "                    (mass_group.mass_diff_median, mass_group.num_psms + 50),\n",
    "                    (mass_group.mass_diff_median + x, y),\n",
    "                    arrowprops={'arrowstyle': '<-', 'linewidth': 1},\n",
    "                    ha='center')\n",
    "\n",
    "ax.set_xlim((-50, 100))\n",
    "\n",
    "ax.yaxis.set_major_formatter(mticker.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "\n",
    "ax.set_xlabel('Precursor mass difference (Da)')\n",
    "ax.set_ylabel(f'Number of PSMs (FDR=1%)')\n",
    "\n",
    "# plt.savefig('mass_diff.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagate identifications\n",
    "\n",
    "We can propagate identifications within clusters by assigning unmodified spectra the same peptide sequence as the majority of identified spectra in the same cluster.\n",
    "\n",
    "We check both identification propagations based on the initial identifications and additional identification propagations based on the new ANN-SoLo identifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_cluster_num_id_propagation(sequences):\n",
    "    num_ids = pd.notnull(sequences).sum()\n",
    "    return len(sequences) - num_ids if num_ids > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_num_id_propagation(clusters):\n",
    "    return clusters.groupby('cluster')['sequence'].apply(\n",
    "        _get_cluster_num_id_propagation).sum()\n",
    "\n",
    "num_id_prop_initial = _get_num_id_propagation(\n",
    "    clusters[(clusters['cluster'] != -1) & ~clusters['ann_solo']])\n",
    "num_id_prop_ann_solo = _get_num_id_propagation(\n",
    "    clusters[clusters['cluster'] != -1]) - num_id_prop_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of propagated initial spectrum identifications: '\n",
    "      f'{num_id_prop_initial:,} '\n",
    "      f'({(num_id_prop_initial / len(clusters)):.2%})')\n",
    "print(f'Number of propagated ANN-SoLo spectrum identifications: '\n",
    "      f'{num_id_prop_ann_solo:,} '\n",
    "      f'({(num_id_prop_ann_solo / len(clusters)):.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618\n",
    "fig, ax = plt.subplots(figsize=(width / 2, height)\n",
    "\n",
    "num_ids = pd.DataFrame([[num_id_massive, num_id_prop_initial,\n",
    "                         num_id_ann_solo, num_id_prop_ann_solo,\n",
    "                         len(clusters[clusters['cluster'] != -1].dropna()),\n",
    "                         len(clusters[clusters['cluster'] == -1])]],\n",
    "                       columns=['original identifications',\n",
    "                                'original identification propagation',\n",
    "                                'ANN-SoLo identifications',\n",
    "                                'ANN-SoLo identification propagation',\n",
    "                                'clustered unidentified',\n",
    "                                'unclustered'])\n",
    "\n",
    "barlist = num_ids.plot.bar(ax=ax, stacked=True, color=[\n",
    "    *sns.color_palette(n_colors=len(num_ids.columns) - 1), 'lightgray'])\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_ylabel('Number of identified spectra')\n",
    "\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h[::-1], l[::-1], loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "ax.yaxis.set_major_formatter(mticker.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "\n",
    "# plt.savefig('id_propagation.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
