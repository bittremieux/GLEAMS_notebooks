{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['GLEAMS_HOME'] = os.path.join(\n",
    "    os.environ['HOME'], 'Projects', 'gleams')\n",
    "# Make sure all code is in the PATH.\n",
    "src_dir = os.path.normpath(os.path.join(os.environ['GLEAMS_HOME'], 'src'))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging.\n",
    "from gleams import logger as glogger\n",
    "glogger.init()\n",
    "# Initialize all random seeds before importing any packages.\n",
    "from gleams import rndm\n",
    "rndm.set_seeds()\n",
    "\n",
    "from gleams import config\n",
    "from gleams.feature import spectrum\n",
    "from gleams.ms_io import ms_io\n",
    "from gleams.nn import embedder, data_generator, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('gleams')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styling.\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='serif')\n",
    "sns.set_palette('Set1')\n",
    "sns.set_context('paper', font_scale=1.3)    # Single-column figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'test'\n",
    "num_pairs = 10_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_generator = data_generator.PairSequence(\n",
    "    os.path.join(\n",
    "        os.environ['GLEAMS_HOME'], 'data', 'feature',\n",
    "        f'feature_{config.massivekb_task_id}_{split}.npz'),\n",
    "    os.path.join(\n",
    "        os.environ['GLEAMS_HOME'], 'data', 'feature',\n",
    "        f'feature_{config.massivekb_task_id}_{split}_pairs_pos.npy'),\n",
    "    os.path.join(\n",
    "        os.environ['GLEAMS_HOME'], 'data', 'feature',\n",
    "        f'feature_{config.massivekb_task_id}_{split}_pairs_neg.npy'),\n",
    "    config.batch_size, nn._get_feature_split(), num_pairs,\n",
    "    False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_metadata = pd.read_parquet(\n",
    "    os.path.join(os.environ['GLEAMS_HOME'], 'data', 'feature',\n",
    "                 f'feature_{config.massivekb_task_id}_{split}.parquet'),\n",
    "    columns=['dataset', 'filename', 'scan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_spectra_from_file(dataset, filename, scans):\n",
    "    spectra = {}\n",
    "    filepath = os.path.join(os.environ['GLEAMS_HOME'], 'data', 'peak',\n",
    "                            dataset, filename)\n",
    "    if not os.path.isfile(filepath):\n",
    "        logger.warning('Missing peak file %s, no spectra read', filename)\n",
    "    else:\n",
    "        for spec in ms_io.get_spectra(filepath, scans):\n",
    "            spectra[f'{dataset}/{filename}/{spec.identifier}'] = \\\n",
    "                spectrum.preprocess(spec, config.fragment_mz_min,\n",
    "                                    config.fragment_mz_max)\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_total = pair_metadata['dataset'].nunique()\n",
    "spectra = []\n",
    "for dataset_i, (dataset, md_dataset) in enumerate(\n",
    "        pair_metadata.groupby('dataset', sort=False), 1):\n",
    "    logging.info('Process dataset %s (%d files) [%3d/%3d]', dataset,\n",
    "                 md_dataset['filename'].nunique(), dataset_i, dataset_total)\n",
    "    spectra.extend(joblib.Parallel(n_jobs=-1, backend='multiprocessing')(\n",
    "        joblib.delayed(_get_spectra_from_file)(dataset, filename,\n",
    "                                               md_file['scan'])\n",
    "        for filename, md_file in md_dataset.groupby(\n",
    "            'filename', sort=False)))\n",
    "spectra = collections.ChainMap(*spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True)\n",
    "def dot(spectra_arr1, spectra_arr2, out, fragment_mz_tol):\n",
    "    for i in nb.prange(spectra_arr1.shape[0]):\n",
    "        out[i] = spectrum.dot(\n",
    "            spectra_arr1[i, 0], spectra_arr1[i, 1],\n",
    "            spectra_arr2[i, 0], spectra_arr2[i, 1],\n",
    "            fragment_mz_tol)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_arr = [], []\n",
    "for pair1, pair2 in itertools.chain(pair_generator.pairs_pos,\n",
    "                                    pair_generator.pairs_neg):\n",
    "    for pair_i, arr_i in zip([pair1, pair2], [0, 1]):\n",
    "        spec = spectra[f\"{pair_metadata.at[pair_i, 'dataset']}/\"\n",
    "                       f\"{pair_metadata.at[pair_i, 'filename']}/\"\n",
    "                       f\"{pair_metadata.at[pair_i, 'scan']}\"]\n",
    "        spectra_arr[arr_i].append(\n",
    "            np.pad(\n",
    "                [spec.mz, spec.intensity],\n",
    "                ((0, 0), (config.max_peaks_used - len(spec.mz), 0)),\n",
    "                'constant'))\n",
    "\n",
    "fragment_mz_tol_high_res, fragment_mz_tol_low_res = 0.05, 0.8\n",
    "labels = np.hstack((np.ones(len(pair_generator.pairs_pos), np.uint8),\n",
    "                    np.zeros(len(pair_generator.pairs_neg), np.uint8)))\n",
    "spectra_arr1 = np.asarray(spectra_arr[0])\n",
    "spectra_arr2 = np.asarray(spectra_arr[1])\n",
    "dot_high_res = dot(\n",
    "    spectra_arr1, spectra_arr2, np.zeros(spectra_arr1.shape[0], np.float32),\n",
    "    fragment_mz_tol_high_res)\n",
    "dot_low_res = dot(\n",
    "    spectra_arr1, spectra_arr2, np.zeros(spectra_arr1.shape[0], np.float32),\n",
    "    fragment_mz_tol_low_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = embedder.Embedder(\n",
    "    config.num_precursor_features, config.num_fragment_features,\n",
    "    config.num_ref_spectra, config.lr, config.model_filename)\n",
    "emb.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_embed, scores_embed = [], []\n",
    "for batch_i in range(len(pair_generator)):\n",
    "    batch_x, batch_y = pair_generator[batch_i]\n",
    "    labels_embed.extend(batch_y)\n",
    "    scores_embed.extend(\n",
    "        emb.siamese_model_parallel.predict(batch_x).reshape(-1))\n",
    "labels_embed = np.asarray(labels_embed)\n",
    "scores_embed = np.asarray(scores_embed)\n",
    "scores_embed = 1 - scores_embed / scores_embed.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump([labels, labels_embed, dot_high_res, dot_low_res, scores_embed],\n",
    "            'aucroc_dot.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels, labels_embed, dot_high_res, dot_low_res, scores_embed =\\\n",
    "#     joblib.load('aucroc_dot.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concentrate_fpr(fpr, alpha):\n",
    "    return (1 - np.exp(-alpha * fpr)) / (1 - np.exp(-alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "# height = width / 1.618\n",
    "fig, ax = plt.subplots(figsize=(width, width))\n",
    "\n",
    "fpr_high_res, tpr_high_res, _ = roc_curve(labels, dot_high_res)\n",
    "croc_fpr_high_res = concentrate_fpr(fpr_high_res, alpha)\n",
    "ax.plot(croc_fpr_high_res, tpr_high_res,\n",
    "        label=f'Dot product high res '\n",
    "              f'(AUCROC = {auc(croc_fpr_high_res, tpr_high_res):.2%})')\n",
    "\n",
    "fpr_low_res, tpr_low_res, _ = roc_curve(labels, dot_low_res)\n",
    "croc_fpr_low_res = concentrate_fpr(fpr_low_res, alpha)\n",
    "ax.plot(croc_fpr_low_res, tpr_low_res,\n",
    "        label=f'Dot product low res '\n",
    "              f'(AUCROC = {auc(croc_fpr_low_res, tpr_low_res):.2%})')\n",
    "\n",
    "fpr_embed, tpr_embed, _ = roc_curve(labels_embed, scores_embed)\n",
    "croc_fpr_embed = concentrate_fpr(fpr_embed, alpha)\n",
    "ax.plot(croc_fpr_embed, tpr_embed,\n",
    "        label=f'Embedding '\n",
    "              f'(AUCROC = {auc(croc_fpr_embed, tpr_embed):.2%})')\n",
    "\n",
    "ax.plot(concentrate_fpr(np.arange(0, 1.01, 0.01), alpha),\n",
    "        np.arange(0, 1.01, 0.01), color='black', linestyle='--')\n",
    "\n",
    "ax.set_xlim([-0.05, 1.05])\n",
    "ax.set_ylim([-0.05, 1.05])\n",
    "\n",
    "ax.set_xlabel('False positive rate')\n",
    "ax.set_ylabel('True positive rate')\n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.3))\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('aucroc_dot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
