{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['GLEAMS_HOME'] = os.path.join(os.environ['HOME'],\n",
    "                                         'Projects/gleams')\n",
    "# Make sure all code is in the PATH.\n",
    "sys.path.append(\n",
    "    os.path.normpath(os.path.join(os.environ['GLEAMS_HOME'], 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import io\n",
    "import json\n",
    "import operator\n",
    "import re\n",
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "from gleams import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MassIVE-KB PSM information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'massivekb_ids'\n",
    "if not os.path.isdir(dir_name):\n",
    "    os.mkdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata for all search task:\n",
    "# MassIVE-KB\n",
    "#     -> Human HCD Spectral Library\n",
    "#     -> View All Search Tasks\n",
    "#     -> Download\n",
    "with urllib.request.urlopen(urllib.request.Request(\n",
    "            'https://proteomics2.ucsd.edu/ProteoSAFe/DownloadResult'\n",
    "            '?task=82c0124b6053407fa41ba98f53fd8d89'\n",
    "            '&view=view_all_search_tasks', method='POST')) \\\n",
    "        as url_search_tasks:\n",
    "    with zipfile.ZipFile(io.BytesIO(url_search_tasks.read())) \\\n",
    "            as zip_search_tasks:\n",
    "        for filename in zip_search_tasks.namelist():\n",
    "            if 'all_search_tasks' in filename:\n",
    "                zip_search_tasks.extract(filename, dir_name)\n",
    "                filename_task_ids = os.path.join(dir_name, filename)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the PSMs for all individual tasks.\n",
    "for task_id in tqdm.tqdm(pd.read_csv(filename_task_ids, sep='\\t',\n",
    "                                     usecols=['search_task_id'],\n",
    "                                     squeeze=True),\n",
    "                         desc='Search results downloaded'):\n",
    "    try:\n",
    "        with urllib.request.urlopen(\n",
    "                f'https://proteomics2.ucsd.edu/ProteoSAFe/status_json.jsp'\n",
    "                f'?task={task_id}') as url_task:\n",
    "            task_type = json.loads(url_task.read().decode())['workflow']\n",
    "            if task_type == 'MULTIPASS_MSGF_PLUS_DB_SEARCH':\n",
    "                # Example: 001812f23bbd4db99f1d4f526b60dbbb\n",
    "                view = 'view_rescored_psms'\n",
    "            elif task_type == 'MSGF-PLUS-SYNTHETIC':\n",
    "                # Example: 0027dc60e863437494475781cd32898e\n",
    "                view = 'group_by_spectrum_merged_result_with_kl_with_ambiguity'\n",
    "            elif task_type == 'MSGF-PLUS-AMBIGUITY':\n",
    "                # Example: 002919d2b7a94058a0d2ae21d3eb1608\n",
    "                view = 'group_by_spectrum'\n",
    "            with urllib.request.urlopen(urllib.request.Request(\n",
    "                        f'https://proteomics2.ucsd.edu/ProteoSAFe/DownloadResult'\n",
    "                        f'?task={task_id}&view={view}', method='POST')) \\\n",
    "                    as url_download:\n",
    "                with zipfile.ZipFile(io.BytesIO(url_download.read())) \\\n",
    "                        as zip_download:\n",
    "                    for filename in zip_download.namelist():\n",
    "                        if any(filename_sub in filename\n",
    "                               for filename_sub in [\n",
    "                                   'view_rescored_psms',\n",
    "                                   'group_by_spectrum_merged_result_with_kl_with_ambiguity',\n",
    "                                   '.mzTab']):\n",
    "                            zip_download.extract(filename, dir_name)\n",
    "                            break\n",
    "    except urllib.error.URLError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine PSMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psms_tsv = pd.concat(\n",
    "    [pd.read_csv(os.path.join(dir_name, filename), sep='\\t',\n",
    "                 usecols=['filename', 'scan', 'sequence', 'decoy'])\n",
    "     for filename in tqdm.tqdm(os.listdir(dir_name), desc='TSV files read')\n",
    "     if (any(filename_sub in filename\n",
    "             for filename_sub in [\n",
    "                 'view_rescored_psms',\n",
    "                 'group_by_spectrum_merged_result_with_kl_with_ambiguity'])\n",
    "         and os.path.getsize(os.path.join(dir_name, filename)) > 0)],\n",
    "    ignore_index=True, sort=False, copy=False)\n",
    "# Remove decoy PSMs.\n",
    "psms_tsv = psms_tsv[psms_tsv['decoy'] == 0]\n",
    "# Remove charge from peptide sequences.\n",
    "regex_no_charge = re.compile('\\.\\d+$')\n",
    "psms_tsv['sequence'] = psms_tsv['sequence'].apply(\n",
    "    functools.partial(regex_no_charge.sub, ''))\n",
    "psms_tsv = psms_tsv[['filename', 'scan', 'sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_run = re.compile('ms_run\\[(\\d+)\\]-location')\n",
    "regex_mod = re.compile('(\\d+)-UNIMOD:(\\d+)')\n",
    "mod_masses = {1: '+42.011', 4: '+57.021', 5: '+43.006', 7: '+0.984',\n",
    "              21: '+79.966', 28: '-17.027', 34: '+14.016', 35: '+15.995'}\n",
    "\n",
    "\n",
    "def _sequence_add_mod(psm):\n",
    "    if pd.isna(psm['modifications']):\n",
    "        return psm['sequence']\n",
    "    else:\n",
    "        mods = [(int(pos), mod_masses[int(mod_i)])\n",
    "                for pos, mod_i in re.findall(regex_mod,\n",
    "                                             psm['modifications'])]\n",
    "        mods = sorted(mods, key=operator.itemgetter(0), reverse=True)\n",
    "        sequence = psm['sequence']\n",
    "        for pos, mod in mods:\n",
    "            sequence = sequence[:pos] + mod + sequence[pos:]\n",
    "        return sequence\n",
    "\n",
    "\n",
    "def read_mztab_psms(filename):\n",
    "    try:\n",
    "        filenames = {}\n",
    "        skiplines = 0\n",
    "        with open(filename) as f_in:\n",
    "            line = next(f_in).strip()\n",
    "            while line.split('\\t', 1)[0] != 'PSH':\n",
    "                line = next(f_in).strip()\n",
    "                if line:\n",
    "                    skiplines += 1\n",
    "                    if 'ms_run' in line:\n",
    "                        run_i = re.search(regex_run, line).group(1)\n",
    "                        filenames[run_i] = (line.rsplit('\\t', 1)[-1]\n",
    "                                            .rsplit('/', 1)[-1])\n",
    "        \n",
    "        psms = pd.read_csv(filename, sep='\\t', header=skiplines,\n",
    "                           usecols=['sequence', 'modifications',\n",
    "                                    'spectra_ref', 'opt_global_decoy'])\n",
    "        psms = psms[psms['opt_global_decoy'] == 0].drop_duplicates()\n",
    "        psms['sequence'] = psms.apply(_sequence_add_mod, axis='columns')\n",
    "        file_scan = psms['spectra_ref'].str.extract(\n",
    "            r'ms_run\\[(?P<file>\\d+)\\]:scan=(?P<scan>\\d+)')\n",
    "        psms['filename'] = file_scan['file'].replace(filenames)\n",
    "        psms['scan'] = file_scan['scan']\n",
    "        return psms[['filename', 'scan', 'sequence']]\n",
    "    except StopIteration:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mztab_dir = os.path.join(dir_name, 'mzTab')\n",
    "psms_mztab = joblib.Parallel(n_jobs=-1)(\n",
    "    joblib.delayed(read_mztab_psms)(os.path.join(mztab_dir, filename))\n",
    "    for filename in os.listdir(mztab_dir)\n",
    "    if filename.lower().endswith('.mztab'))\n",
    "psms_mztab = pd.concat(psms_mztab, ignore_index=True, sort=False, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psms = (pd.concat([psms_tsv, psms_mztab], ignore_index=True, copy=False)\n",
    "        .drop_duplicates(['filename', 'scan']))\n",
    "psms['scan'] = psms['scan'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with spectrum metadata to add precursor m/z and charge information.\n",
    "psms = pd.merge(\n",
    "    pd.read_parquet(\n",
    "        os.path.join(os.environ['GLEAMS_HOME'], 'data', 'embed',\n",
    "                     f'embed_{config.massivekb_task_id}.parquet')),\n",
    "    psms, 'outer', ['filename', 'scan'], copy=False).dropna()\n",
    "psms['scan'] = psms['scan'].astype(np.int64)\n",
    "psms['charge'] = psms['charge'].astype(np.int64)\n",
    "psms = (psms[['dataset', 'filename', 'scan', 'sequence', 'charge', 'mz']]\n",
    "        .sort_values(['dataset', 'filename', 'scan']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psms.to_parquet(\n",
    "    os.path.join(os.environ['GLEAMS_HOME'], 'data', 'metadata',\n",
    "                 f'massivekb_ids_{config.massivekb_task_id}.parquet'),\n",
    "    index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
